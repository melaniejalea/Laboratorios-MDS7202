{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "b248ca1993694afd90401e60c7f4b53b": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_8302ee2ded67482090417663d456adcf",
            "msg_id": "",
            "outputs": [
              {
                "output_type": "display_data",
                "data": {
                  "text/plain": "\u001b[35m 100%\u001b[0m \u001b[38;2;249;38;114m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[38;2;249;38;114m‚ï∏\u001b[0m \u001b[32m199,955/200,000 \u001b[0m [ \u001b[33m0:06:29\u001b[0m < \u001b[36m0:00:01\u001b[0m , \u001b[31m501 it/s\u001b[0m ]\n",
                  "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080\"> 100%</span> <span style=\"color: #f92672; text-decoration-color: #f92672\">‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ï∏</span> <span style=\"color: #008000; text-decoration-color: #008000\">199,955/200,000 </span> [ <span style=\"color: #808000; text-decoration-color: #808000\">0:06:29</span> &lt; <span style=\"color: #008080; text-decoration-color: #008080\">0:00:01</span> , <span style=\"color: #800000; text-decoration-color: #800000\">501 it/s</span> ]\n</pre>\n"
                },
                "metadata": {}
              }
            ]
          }
        },
        "8302ee2ded67482090417663d456adcf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bc0902664d034f73bf68eb28603a21a2": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_9e6867520f7145b7bb513e2204466cec",
            "msg_id": "",
            "outputs": [
              {
                "output_type": "display_data",
                "data": {
                  "text/plain": "\u001b[35m 100%\u001b[0m \u001b[38;2;249;38;114m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[38;2;249;38;114m‚ï∏\u001b[0m \u001b[32m9,999/10,000 \u001b[0m [ \u001b[33m0:02:44\u001b[0m < \u001b[36m0:00:01\u001b[0m , \u001b[31m61 it/s\u001b[0m ]\n",
                  "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080\"> 100%</span> <span style=\"color: #f92672; text-decoration-color: #f92672\">‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ï∏</span> <span style=\"color: #008000; text-decoration-color: #008000\">9,999/10,000 </span> [ <span style=\"color: #808000; text-decoration-color: #808000\">0:02:44</span> &lt; <span style=\"color: #008080; text-decoration-color: #008080\">0:00:01</span> , <span style=\"color: #800000; text-decoration-color: #800000\">61 it/s</span> ]\n</pre>\n"
                },
                "metadata": {}
              }
            ]
          }
        },
        "9e6867520f7145b7bb513e2204466cec": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**<h1><center>Laboratorio 11: LLM y Agentes Aut√≥nomos ü§ñ</center></h1>**\n",
        "\n",
        "<center><strong>MDS7202: Laboratorio de Programaci√≥n Cient√≠fica para Ciencia de Datos</strong></center>"
      ],
      "metadata": {
        "id": "PyPTffTLug7i"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UD8X1uhGzAHq",
        "cell_id": "737a4540885f41acb34b9863a968b907",
        "deepnote_cell_type": "markdown"
      },
      "source": [
        "### **Cuerpo Docente:**\n",
        "\n",
        "- Profesor: Ignacio Meza, Sebastian Tinoco\n",
        "- Auxiliar: Catherine Benavides, Consuelo Rojas\n",
        "- Ayudante: Eduardo Moya, Nicol√°s Ojeda"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tXflExjqzAHr",
        "cell_id": "e4a6f26138654eb49ee963fb4c7ecf46",
        "deepnote_cell_type": "markdown"
      },
      "source": [
        "### **Equipo:**\n",
        "\n",
        "- Nombre de alumno 1: Melanie Pe√±a Torres\n",
        "- Nombre de alumno 2: Valentina Rojas Osorio\n",
        "\n",
        "**SUPER IMPORTANTE** - notebooks sin nombre no ser√°n revisados"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AD-V0bbZzAHr",
        "owner_user_id": "badcc427-fd3d-4615-9296-faa43ec69cfb",
        "cell_id": "7dd4aaebd4f44063aedbb47ea36349a5",
        "deepnote_cell_type": "markdown"
      },
      "source": [
        "### **Link de repositorio de GitHub:** [Link](https://github.com/melaniejalea/Laboratorios-MDS7202/tree/lab11)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EcnsiQMkzAHr",
        "cell_id": "abe08e51696a471e8cc8ac1fa4216f0b",
        "deepnote_cell_type": "markdown"
      },
      "source": [
        "### **Indice**\n",
        "\n",
        "1. [Temas a tratar](#Temas-a-tratar:)\n",
        "3. [Descripcci√≥n del laboratorio](#Descripci√≥n-del-laboratorio.)\n",
        "4. [Desarrollo](#Desarrollo)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6uBLPj1PzAHs",
        "cell_id": "0174e9377ebb43eaa0d12718db4c81ec",
        "deepnote_cell_type": "markdown"
      },
      "source": [
        "## **Temas a tratar**\n",
        "\n",
        "- Implementaci√≥n de modelos de LLM y Reinforcement Learning.\n",
        "- Utilizaci√≥n e implementaci√≥n de agentes.\n",
        "\n",
        "## **Reglas:**\n",
        "\n",
        "- **Grupos de 2 personas**\n",
        "- Fecha de entrega: 7 d√≠as desde la publicaci√≥n, 3 d√≠as de atraso con 1 punto de descuento c/u.\n",
        "- Instrucciones del lab el viernes a las 16:15 en formato online. Asistencia no es obligatoria.\n",
        "- Prohibidas las copias. Cualquier intento de copia ser√° debidamente penalizado con el reglamento de la escuela.\n",
        "- Tienen que subir el laboratorio a u-cursos y a su repositorio de github. Labs que no est√©n en u-cursos no ser√°n revisados. Recuerden que el repositorio tambi√©n tiene nota.\n",
        "- Cualquier duda fuera del horario de clases al foro. Mensajes al equipo docente ser√°n respondidos por este medio.\n",
        "Pueden usar cualquer material del curso que estimen conveniente.\n",
        "\n",
        "### **Objetivos principales del laboratorio**\n",
        "\n",
        "- Generar un modelo LLM generativo interactivo.\n",
        "- Entrenar un modelo de Reinforce Learning.\n",
        "\n",
        "El laboratorio deber√° ser desarrollado sin el uso indiscriminado de iteradores nativos de python (aka \"for\", \"while\"). La idea es que aprendan a exprimir al m√°ximo las funciones optimizadas que nos entrega `pandas`, las cuales vale mencionar, son bastante m√°s eficientes que los iteradores nativos sobre DataFrames."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **1. Large Language Models (4.0 puntos)**"
      ],
      "metadata": {
        "id": "Is4P4NDMurx6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p align=\"center\">\n",
        "  <img src=\"https://trestristescriticos.com/wp-content/uploads/2021/07/telefono-gratuito-cinesur.jpg\" width=\"350\">\n",
        "</p>"
      ],
      "metadata": {
        "id": "tJ3yV96HwN75"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Joaqu√≠n no es un aficionado del cine, pero a principios de a√±o, se propuso ver m√°s peliculas para poder tener m√°s temas de conversaci√≥n con sus amigos y familia. Sin embargo, ya es junio y Joaqu√≠n no ha visto ninguna pelicula nueva o relevante de las que ten√≠a en su lista y su reuni√≥n familiar bi-anual se acerca y necesita la mayor informaci√≥n que pueda recopilar de dichas peliculas sin tener que verlas.\n",
        "\n",
        "Para esto, usted con su compa√±erx, tendr√° que crear una aplicaci√≥n utilizando LangChain.\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "kB8z1qrGww4o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Instalaci√≥n de librer√≠as**\n",
        "\n",
        "Para la creaci√≥n de la aplicaci√≥n, se utilizara un modelo de lenguaje (LLM) ofrecido gratuitamente por Google.\n",
        "\n",
        "Para ello, se utilizar√° la API de Gemini, por lo que si no tienen acceso, se pueden crear una cuenta en el siguiente [enlace a Google AI](https://ai.google.dev/). Ah√≠, ir a la pesta√±a superior y seleccione la opci√≥n que dice ``Gemini API``.\n",
        "\n",
        "<img src='https://gitlab.com/imezadelajara/datos_clase_7_mds7202/-/raw/main/misc_images/Screenshot_2024-06-13_at_12.42.32_PM.png' width='450' />\n",
        "\n",
        "Luego, seleccione el bot√≥n que dice ``Get API key in Google AI Studio`` y hacer click en ``Crear clave de API`` para generar la llave con la que se podr√° consultar al modelo de lenguaje.\n",
        "\n",
        "<img src='https://gitlab.com/imezadelajara/datos_clase_7_mds7202/-/raw/main/misc_images/Screenshot_2024-06-13_at_12.45.10_PM.png?ref_type=heads' width='450' />\n",
        "\n",
        "**Importante:** Debido a las restricciones de esta API, lo ideal es utilizar la llave a la API de manera personal.\n",
        "\n",
        "\n",
        "Para mayor informaci√≥n sobre **LangChain**, pueden revisar la documentaci√≥n en el [presente enlace](https://python.langchain.com/v0.2/docs/tutorials/summarization/ )."
      ],
      "metadata": {
        "id": "dOIeEP9Ey_lF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install langchain\n",
        "!pip install langchain_google_genai\n",
        "!pip install langchain-community\n",
        "!pip install langchain-experimental\n",
        "!pip install sentence-transformers\n",
        "!pip install faiss-cpu"
      ],
      "metadata": {
        "id": "LLbYWURudw2c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "82aJnnH0b0Oo"
      },
      "outputs": [],
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "import os\n",
        "\n",
        "os.environ[\"GOOGLE_API_KEY\"] = \"AIzaSyD904omnTtarZIyb9AAzjcbX8Gp1po7rMs\"\n",
        "llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **1.1 Carga y limpieza (0.5 puntos)**"
      ],
      "metadata": {
        "id": "kUgbzVtWUYq2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para iniciar su titanica tarea de ense√±arle a Joaqu√≠n sobre las mejores peliculas del √∫ltimo tiempo, tiene que revisar los script de las siguientes 3 peliculas:\n",
        "* Dune 2\n",
        "* Under Paris\n",
        "* Joker\n",
        "\n",
        "Debe encontrar un patr√≥n y obtener solamente el gui√≥n de las pel√≠culas. Para ello se recomienda utilizar m√©todos de b√∫squeda y reemplazo que tienen los ``string`` en Python. Adicionalmente, puede usar filtros de expresiones regulares.\n",
        "\n",
        "Posterior a la limpieza de los guiones, debe considerar que el patr√≥n se repite y es generalizable. ‚úÖ\n"
      ],
      "metadata": {
        "id": "6I10Li9a7nez"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Scripts de peliculas\n",
        "dune2_script=\"https://scrapsfromtheloft.com/movies/dune-part-two-2024-transcript/\"\n",
        "underparis_script=\"https://scrapsfromtheloft.com/movies/under-paris-2024-transcript/\"\n",
        "joker_script=\"https://scrapsfromtheloft.com/movies/joker-2019-transcript/\""
      ],
      "metadata": {
        "id": "HpYuwfO_F0pD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.document_loaders import WebBaseLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter"
      ],
      "metadata": {
        "id": "uqKYYPHhOCCF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_website_data(url):\n",
        "  '''\n",
        "  Escriba su c√≥digo ac√°\n",
        "  '''\n",
        "  loader = WebBaseLoader(url)\n",
        "  docs = loader.load()\n",
        "  website_data = docs[0].page_content\n",
        "  return website_data"
      ],
      "metadata": {
        "id": "qax6fONAOCsC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "script_dune = load_website_data(dune2_script)\n",
        "script_underparis = load_website_data(underparis_script)\n",
        "script_joker = load_website_data(joker_script)"
      ],
      "metadata": {
        "id": "M5rvAJ5sOEmY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "script_dune[:500]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "id": "vgr_5nnbOU63",
        "outputId": "f237da3c-9c3e-4f41-bb7a-9c33a2e41afe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n\\n\\n\\n\\n\\n\\n\\nDune: Part Two (2024) | Transcript - Scraps from the loft\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\r\\n\\t\\tSkip to content\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nMOVIES\\n\\nMOVIE REVIEWS\\nMOVIE TRANSCRIPTS\\n\\n\\nTV SERIES\\n\\nTV SHOW TRANSCRIPTS\\n\\n\\nCOMEDY\\n\\nSTAND-UP COMEDY TRANSCRIPTS\\nGEORGE CARLIN\\nDAVE CHAPPELLE\\n\\n\\nINTERVIEWS\\n\\nPLAYBOY INTERVIEWS\\n\\n\\nMUSIC\\nHISTORY\\nBOOKS\\nOPINIONS\\n \\n\\n Menu\\n\\n\\nMOVIES\\n\\nMOVIE REVIEWS\\nMOVIE TRANSCRIPTS\\n\\n\\nTV SERIES\\n\\nTV SHOW TRANSCRIPTS\\n\\n\\nCOMEDY\\n\\nSTAND-UP C'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 163
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "script_underparis[:500]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "id": "PzS-UJxZQ1cd",
        "outputId": "59a84178-f840-428b-e7d1-372def28b550"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n\\n\\n\\n\\n\\n\\n\\nUnder Paris (2024) | Transcript - Scraps from the loft\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\r\\n\\t\\tSkip to content\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nMOVIES\\n\\nMOVIE REVIEWS\\nMOVIE TRANSCRIPTS\\n\\n\\nTV SERIES\\n\\nTV SHOW TRANSCRIPTS\\n\\n\\nCOMEDY\\n\\nSTAND-UP COMEDY TRANSCRIPTS\\nGEORGE CARLIN\\nDAVE CHAPPELLE\\n\\n\\nINTERVIEWS\\n\\nPLAYBOY INTERVIEWS\\n\\n\\nMUSIC\\nHISTORY\\nBOOKS\\nOPINIONS\\n \\n\\n Menu\\n\\n\\nMOVIES\\n\\nMOVIE REVIEWS\\nMOVIE TRANSCRIPTS\\n\\n\\nTV SERIES\\n\\nTV SHOW TRANSCRIPTS\\n\\n\\nCOMEDY\\n\\nSTAND-UP COMED'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "script_joker[:500]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "id": "DyeNURRMbRN6",
        "outputId": "4f38e3c9-feee-4911-c40d-dc74515dc98e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n\\n\\n\\n\\n\\n\\n\\nJoker (2019) | Transcript - Scraps from the loft\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\r\\n\\t\\tSkip to content\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nMOVIES\\n\\nMOVIE REVIEWS\\nMOVIE TRANSCRIPTS\\n\\n\\nTV SERIES\\n\\nTV SHOW TRANSCRIPTS\\n\\n\\nCOMEDY\\n\\nSTAND-UP COMEDY TRANSCRIPTS\\nGEORGE CARLIN\\nDAVE CHAPPELLE\\n\\n\\nINTERVIEWS\\n\\nPLAYBOY INTERVIEWS\\n\\n\\nMUSIC\\nHISTORY\\nBOOKS\\nOPINIONS\\n \\n\\n Menu\\n\\n\\nMOVIES\\n\\nMOVIE REVIEWS\\nMOVIE TRANSCRIPTS\\n\\n\\nTV SERIES\\n\\nTV SHOW TRANSCRIPTS\\n\\n\\nCOMEDY\\n\\nSTAND-UP COMEDY TRA'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_text_before_marker(text):\n",
        "    '''\n",
        "    Escriba su c√≥digo ac√°\n",
        "    '''\n",
        "    '''\n",
        "    Notamos que hay caracteres como esto al usar la √∫ltima funci√≥n:\n",
        "    \\n[all laughing]\\n[speaking in Chakobsa]\n",
        "    y adem√°s hay que tener presente el * como token\n",
        "    de inicio, gracias NLP!\n",
        "    '''\n",
        "    start_markers = [\"* * *\", \"\\n[\"]\n",
        "    start_position = -1\n",
        "    for marker in start_markers:\n",
        "        position = text.find(marker)\n",
        "        if position != -1:\n",
        "            start_pos = position + len(marker)\n",
        "            break\n",
        "    if start_pos == -1:\n",
        "        start_pos = 0\n",
        "    text_out = text[start_pos:]\n",
        "    '''\n",
        "    Explorando los scripts usando la ultima funci√≥n\n",
        "    notamos que el script termina alrededor del token de More dado que luego\n",
        "    lo que se tiene son anuncios para conseguir m√°s scripts y rcibir anuncios\n",
        "    \\n[breathing heavily]\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nMore:\\n\\nDenis Villeneuve, Dune: Part Two, Movie Transcripts \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSHARE THIS ARTICLE \\n\\n\\n\\n\\n\\n\\n\\n \\n\\n\\n\\n\\n\\n\n",
        "     \\n\\n\\n\\n\\n\\n \\n\\n\\n\\n\\n\\n \\n\\n\\n\\n\\n\\n \\n\\n\\n\\n\\n\\n \\n\\n\\n\\n\\n\\n \\n\\n\\n\\n\\n\\n \\n\\n\\n\\n\\n\\n \\n\\n\\n\\n\\n\\n \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nLeave a Comment Cancel ReplyYour email address will not be published\n",
        "    '''\n",
        "    end_marker = \"\\n\\nMore:\\n\\n\"\n",
        "    end_position = text_out.find(end_marker)\n",
        "    if end_position != -1:\n",
        "        text_out = text_out[:end_position]\n",
        "    text_out = text_out.strip()\n",
        "    return text_out"
      ],
      "metadata": {
        "id": "XUfvpxPD8v5X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clean_dune = remove_text_before_marker(script_dune)\n",
        "clean_underparis = remove_text_before_marker(script_underparis)\n",
        "clean_joker = remove_text_before_marker(script_joker)"
      ],
      "metadata": {
        "id": "QIHssMSuOl1H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clean_dune[:500]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "c-wLQR8oPph6",
        "outputId": "1c8006bc-119d-4818-fb5e-f642b709e188"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'male voice in alien language] Power over Spice is power over all\\n[suspenseful music playing]\\n[Irulan] Imperial Diary. Year 10,191. Third comment. The battle for Arrakis took everyone by surprise. There were no witnesses.\\n[somber music playing]\\nThe Harkonnen operation was perpetrated overnight, without warning or declaration of war. By morning, the Atreides were no more. All died in the dark.\\nAnd the Emperor said‚Ä¶ nothing. Since that night, my father has not been the same. Nor have I. His inactio'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "clean_underparis[:500]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "XkI1chH3Q6vB",
        "outputId": "e8dffee6-083b-4446-8cdb-bc3faa7f4422"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'[water swirling, burbling]\\n‚ÄúIT IS NOT THE STRONGEST OF THE SPECIES THAT SURVIVES, NOR THE MOST INTELLIGENT, IT IS THE ONE THAT IS MOST ADAPTABLE TO CHANGE.‚Äù\\nBASED ON THE WORK OF CHARLES DARWIN\\n[calm, mysterious music playing]\\n[music builds]\\n[bubbles burbling]\\n[epic music intensifies]\\nNORTH PACIFIC OCEAN\\nMISSION OCEAN ORIGINS PROJECT ‚ÄúEVOLUTION‚Äù\\n[woman 1] I‚Äôm here on what‚Äôs known as the ‚Äúseventh continent,‚Äù a mass of refuse and garbage over 3 million kilometers in size, four to six times bigger t'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "clean_joker[:500]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "oUoNjSDrbUd7",
        "outputId": "82ee2b44-09e5-4334-e8a9-0ca29accfe29"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'[news anchor on radio] The news never ends.\\nThis is 1080 GCR.\\nYou get all the news you need, all day long.\\nGood morning.\\nIt‚Äôs 42 degrees at 10:30 on this Thursday, October 15th.\\nI‚Äôm Stan L. Brooks, and here‚Äôs what‚Äôs happening.\\nIt‚Äôs day 18 of the garbage strike, with 10,000 tons of garbage piling up every day.\\nEven the nicest sections of the city are looking like slums.\\nHealth Commissioner Edward O‚ÄôRourke is declaring a city-wide state of emergency for the first time in decades.\\n[O‚ÄôRourke] There‚Äô'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **1.2 Aplicaci√≥n (3.5 puntos)**\n",
        "\n",
        "Luego de limpiar los guiones, es posible generar la aplicaci√≥n deseada con el LLM. Esta aplicaci√≥n tiene que ser capaz de realizar las siguientes tareas.\n",
        "\n",
        "1. Utilizando una plantilla sobre el nombre del archivo o la URL, identifique el supuesto nombre de la pel√≠cula.\n",
        "\n",
        "2. Genere un resumen en espa√±ol de la pel√≠cula y una nota evaluativa sobre la misma. El resumen debe tener entre 3 a 5 p√°rrafos. Adem√°s, obtener una evaluaci√≥n de la pel√≠cula con una calificaci√≥n del 1 al 10, utilizando una LLM y el contexto entregado"
      ],
      "metadata": {
        "id": "7Btad-nZ9EyS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **1.2.1 T√≠tulo de la pel√≠cula (0.5 puntos)** ‚úÖ\n",
        "\n",
        "Para obtener el t√≠tulo, utilic√© la siguiente plantilla:\n",
        "```\n",
        " template = \"\"\"\n",
        "  What is the movie that appears in the description of this file or url?\n",
        "  You only give me the movie name, nothing more.\n",
        "  document/url: {script_path_url}\n",
        "  \"\"\"\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "QcS80oN2-Gq4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import LLMChain"
      ],
      "metadata": {
        "id": "p5_PXlUag06l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_movie_title(script_path_url):\n",
        "  '''\n",
        "  Escriba su c√≥digo ac√°\n",
        "  '''\n",
        "  template = \"\"\"\n",
        "  What is the movie that appears in the description of this file or url?\n",
        "  You only give me the movie name, nothing more.\n",
        "  document/url: {script_path_url}\n",
        "  \"\"\"\n",
        "  prompt_template = PromptTemplate.from_template(template)\n",
        "  prompt_chain = LLMChain(llm=llm, prompt=prompt_template)\n",
        "  result = prompt_chain.invoke({'script_path_url':script_path_url})\n",
        "  return result['text'].strip()"
      ],
      "metadata": {
        "id": "yNIU3mmh-F5W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "script1_title = get_movie_title(dune2_script)\n",
        "script1_title"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Q1n5uIchfNvy",
        "outputId": "ced2d0ef-376e-46b0-ffa6-0e65e87c8fb0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Dune: Part Two'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "script2_title = get_movie_title(underparis_script)\n",
        "script2_title"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "7MKjZ1hWhzKF",
        "outputId": "0b8f1e1d-19b1-4b80-8eae-c4209ed83be1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Under Paris'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "script3_title = get_movie_title(joker_script)\n",
        "script3_title"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "wVCHp5Jmh3qY",
        "outputId": "495ef268-aa8e-4964-9845-930b3ae342f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Joker'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **1.2.2 Resumen (1.0 puntos)** ‚úÖ\n",
        "\n",
        "Como se vi√≥ en clases, las LLM no pueden manejar cadenas de texto muy largas, esto es debido a que, dependiendo de su naturaleza, solo manejan ventanas de contexto que estan asociadas a caracteristicas de la red y del entrenamiento utilizado.\n",
        "\n",
        "Por ello, es altamente importante que si se desea hacer un resumen del texto, este se haga realizando un tipo de map/reduce sobre el texto. De manera que en cada una de las iteraciones se vaya disminuyendo el tama√±o del texto, pero hay que tener cuidado con que le modelo vaya guardando el contexto de escenas previas."
      ],
      "metadata": {
        "id": "muDXLfr0CabX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import MapReduceDocumentsChain, ReduceDocumentsChain\n",
        "from langchain.chains import StuffDocumentsChain, LLMChain\n",
        "from langchain.chains.combine_documents.stuff import StuffDocumentsChain\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter"
      ],
      "metadata": {
        "id": "9sxX87HpDZiV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#No cambiar funci√≥n\n",
        "\n",
        "def map_reduce_text(script, map_template, reduce_template):\n",
        "\n",
        "  # Map\n",
        "  \"\"\"\n",
        "  map_prompt, crear el prompt desde el template\n",
        "  map_chain, crear la cadena desde el prompt\n",
        "  \"\"\"\n",
        "  map_prompt = PromptTemplate.from_template(map_template)\n",
        "  map_chain = LLMChain(llm=llm, prompt=map_prompt)\n",
        "  # Reduce\n",
        "  \"\"\"\n",
        "  reduce_prompt, crear el prompt desde el template\n",
        "  reduce_chain, crear la cadena desde el prompt\n",
        "  \"\"\"\n",
        "  reduce_prompt = PromptTemplate.from_template(reduce_template)\n",
        "  reduce_chain = LLMChain(llm=llm, prompt=reduce_prompt)\n",
        "  # Combine\n",
        "  \"\"\"\n",
        "  Combinar y reducir los documentos, utilizar StuffDocumentsChain\n",
        "  y ReduceDocuentsChain con un m√°ximo de 4000 tokens\n",
        "  \"\"\"\n",
        "  combine_documents_chain = StuffDocumentsChain(\n",
        "    llm_chain=reduce_chain, document_variable_name=\"script\")\n",
        "\n",
        "  reduce_documents_chain = ReduceDocumentsChain(\n",
        "    combine_documents_chain=combine_documents_chain,\n",
        "    collapse_documents_chain=combine_documents_chain,\n",
        "    token_max=4000,)\n",
        "\n",
        "  # Map/Reduce\n",
        "  \"\"\"\n",
        "  Uilizar MapReduceDocumentsChain\n",
        "  \"\"\"\n",
        "  map_reduce_chain = MapReduceDocumentsChain(\n",
        "    llm_chain=map_chain,\n",
        "    reduce_documents_chain=reduce_documents_chain,\n",
        "    document_variable_name=\"script\",\n",
        "    return_intermediate_steps=False,)\n",
        "\n",
        "\n",
        "  # Text splitter\n",
        "  \"\"\"\n",
        "  Usar RecursiveCharacterTextSplitter\n",
        "  \"\"\"\n",
        "  text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
        "    chunk_size=1000, chunk_overlap=0)\n",
        "\n",
        "  # Resultado\n",
        "  split_script = text_splitter.create_documents([script])\n",
        "  result = map_reduce_chain.invoke(split_script)\n",
        "\n",
        "  return result[\"output_text\"]"
      ],
      "metadata": {
        "id": "jkxFMnCFDcgl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install tiktoken"
      ],
      "metadata": {
        "id": "QEv_uu_jrLy_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# crear templates\n",
        "\n",
        "map_template_summary = \"\"\"The following is a script from a movie\n",
        "{script}\n",
        "Based on this script, please identify the main themes from it.\n",
        "Helpful Answer:\"\"\"\n",
        "\n",
        "reduce_template_summary =\"\"\"The following is a script from a movie:\n",
        "{script}\n",
        "Take it and distill it into a final, consolidated summary of the main themes.\n",
        "Name the movie and then include it's summary.This summary must be in between 3 or 5 paragraphs.\n",
        "It also needs to include a review for this movie rating it from a 1 to a 10, 10 being the highest score.\n",
        "Helpful Answer:\"\"\""
      ],
      "metadata": {
        "id": "HsEJR0IGEZ8V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# imprimir resumenes de pel√≠culas.\n",
        "answer_summary = map_reduce_text(clean_dune, map_template_summary, reduce_template_summary)\n",
        "print(answer_summary)"
      ],
      "metadata": {
        "id": "ijib42GaIFSI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee2a3306-7f7c-44b3-c2f7-517df684a1f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "## Dune (2021)\n",
            "\n",
            "\"Dune\" is a sprawling epic that plunges viewers into a universe of political intrigue, ecological wonder, and spiritual awakening.  The film follows Paul Atreides, a young noble thrust into the center of a galactic power struggle over the control of a precious resource known as \"spice.\"  Forced to flee his home after a betrayal, Paul finds refuge among the Fremen, a fierce desert people who hold the key to his survival and destiny. \n",
            "\n",
            "As Paul adapts to the harsh environment and embraces the Fremen culture, he begins to understand the power of belief and the weight of his own prophecy. The film masterfully explores themes of power, destiny, and faith. Paul grapples with his prophetic abilities, the weight of his destiny, and the influence of the Bene Gesserit, a powerful organization that has been manipulating events for generations. The Fremen, with their deep reverence for the desert and their unwavering belief in Paul's prophesied role, represent the power of faith and the resilience of a people fighting for their survival.  \n",
            "\n",
            "\"Dune\" is a visually stunning and intellectually stimulating film that captivates the audience with its epic scope and complex characters. The film's masterful blend of science fiction, political drama, and spiritual exploration creates a truly immersive experience. The performances are captivating, particularly Timoth√©e Chalamet as Paul Atreides, whose journey from naive noble to a potential messiah is both compelling and nuanced. The film's breathtaking visuals and haunting score create a truly unforgettable cinematic experience. \n",
            "\n",
            "**Rating:** 9/10 \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "answer_summary2 = map_reduce_text(clean_underparis, map_template_summary, reduce_template_summary)\n",
        "print(answer_summary2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NpNdYVcCshgD",
        "outputId": "ca75d9c3-c0b5-47ac-8ab6-8ce8929747ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain_google_genai.chat_models:Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
            "WARNING:langchain_google_genai.chat_models:Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "## Evolution: A Dive into Environmental Crisis and Human Resilience\n",
            "\n",
            "\"Evolution\" is a captivating film that takes viewers on a journey through a world dramatically altered by human impact on the environment.  The film opens with a stark portrayal of the \"seventh continent,\" a massive plastic island in the Pacific Ocean, setting the stage for a narrative that explores the consequences of pollution and the struggle for survival in a rapidly changing world.  The story centers around a team of scientists dedicated to understanding the ocean's mysteries, but their research is conducted within an environment heavily impacted by human activity.  Through their encounters with sharks, creatures known for their resilience and ability to thrive in challenging environments, the film explores the themes of adaptation and survival in the face of adversity. \n",
            "\n",
            "\"Evolution\" offers a thought-provoking exploration of humanity's relationship with nature, highlighting both the beauty and the fragility of the natural world.  It serves as a stark reminder of the interconnectedness of all life and the consequences of our actions on the planet.  The film leaves viewers pondering the importance of understanding and protecting the environment for future generations, urging us to consider the choices we make and strive for a more sustainable future. \n",
            "\n",
            "**Review:**\n",
            "\n",
            "\"Evolution\" is a visually stunning and emotionally resonant film that delivers a powerful message about the urgency of environmental protection. The film's exploration of complex themes, such as the impact of human pollution, the resilience of life, and the scientific quest to understand the natural world, is both timely and relevant. While the film's pacing might be slow at times, the overall impact is undeniable. \"Evolution\" is a must-see for anyone concerned about the future of our planet and the delicate balance of life on Earth.\n",
            "\n",
            "**Rating:** 9/10 \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Por alguna raz√≥n por m√°s que pidamos esta pel√≠cula \"Under Paris\" nos entrega otras pel√≠culas, asumimos por que se estreno este a√±o, por lo que el modelo no funciona bien para √©l. Fecha de estreno inicial de Under Paris: 5 de junio de 2024"
      ],
      "metadata": {
        "id": "XS93Us4VwbuJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "answer_summary3 = map_reduce_text(clean_joker, map_template_summary, reduce_template_summary)\n",
        "print(answer_summary3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rX1jMuNXtXcW",
        "outputId": "8e460e70-2cde-4e6a-af23-9e076b3e0cf2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain_google_genai.chat_models:Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "## Joker (2019)\n",
            "\n",
            "\"Joker\" is a chilling and thought-provoking exploration of mental illness, social inequality, and the potential for violence when individuals feel ignored and marginalized.  The film follows Arthur Fleck, a struggling clown with a mental health condition, as he navigates a world that seems determined to crush him. Arthur's descent into madness is fueled by a combination of societal neglect, a lack of support, and a growing sense of alienation. The film powerfully depicts the devastating consequences of mental illness when individuals are denied the resources and compassion they need. \n",
            "\n",
            "Beyond the individual struggles of Arthur, \"Joker\" also paints a bleak picture of a society on the brink of collapse. The film highlights the stark divide between the wealthy elite and the struggling lower class, showcasing the corruption of power and the hypocrisy of those who hold it.  Arthur's resentment towards the \"pricks\" in Gotham City, particularly Thomas Wayne, a symbol of privilege and wealth, reflects a broader critique of the societal structures that perpetuate injustice and inequality.  The film suggests that when individuals are left to suffer in a system that ignores their needs, they may turn to violence as a means of expressing their anger and frustration. \n",
            "\n",
            "\"Joker\" is a powerful and unsettling film that lingers in the mind long after the credits roll. Joaquin Phoenix delivers a tour-de-force performance as Arthur Fleck, capturing the character's descent into madness with chilling accuracy. The film's dark and gritty aesthetic perfectly reflects the bleakness of Arthur's world, creating a sense of unease and dread. While some may find the film's violence disturbing, it serves a purpose, highlighting the consequences of social neglect and the potential for individuals to become radicalized when they feel unheard and unseen.  \"Joker\" is a complex and thought-provoking film that raises important questions about mental health, social inequality, and the responsibility we have to each other. \n",
            "\n",
            "**Rating:** 9/10 \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Adicionalmente, Joaqu√≠n sabe que su primo favorito le gusta ``Dune: Part 2`` por lo que le gustar√≠a tener mayor informaci√≥n al respecto, para ello realice las siguientes tareas:\n",
        "\n",
        "\n",
        "3. Genere un gr√°fico que muestre los personajes de la pel√≠cula con m√°s apariciones en la misma. ‚úÖ\n",
        "4. Genere una tabla en pandas con los 3 personajes que m√°s aparecen, indicando el nombre del actor y su edad actual m√°s uno (ojo edad + 1).\n",
        "5. Cree una funci√≥n que responda preguntas sobre la pel√≠cula bas√°ndose en la informaci√≥n del texto entregado (OJO: las preguntas y salidas deben ser en espa√±ol). Luego, responda las siguientes preguntas:\n",
        "* ¬øQu√© y qui√©n es Lisan al-Gaib?\n",
        "* ¬øQu√© personaje no cree en la profec√≠a pero es parte de ella?\n",
        "* ¬øCu√°l es el objetivo de Feyd-Rautha?\n",
        "6. Utilizando el top 3 de personajes que m√°s aparecen en la pel√≠cula, genere con el modelo LLM y utilizando el contexto del guion, las 6 estad√≠sticas que demuestren las habilidades de los personajes: Intelligence, Strength, Charisma, Wisdom, Emotional Resilience, y Creativity."
      ],
      "metadata": {
        "id": "dD7YHYZSIWbJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **1.2.3 Personajes (0.5 puntos)**\n",
        "\n",
        "En la siguiente secci√≥n, tiene que entregar un template de personajes y redicci√≥n"
      ],
      "metadata": {
        "id": "e_vdMMceJZBu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "map_template_characters = \"\"\"The following is a movie script:\n",
        "{script}\n",
        "Identify all characters mentioned in the script.\n",
        "Characters appear in the format \"[name_character]\" within the text.\n",
        "Ignore every other name that does not follow this format.\n",
        "Do not add any additional information to get the names, like sources\n",
        "from books or comics of the same name.\n",
        "Helpful Answer:\n",
        "\"\"\"\n",
        "\n",
        "reduce_template_characters = \"\"\"Here are summaries from the script:\n",
        "{script}\n",
        "From these summaries, provide a final list in Python list format stored in a variable named 'characters_name'.\n",
        "The list must only contain names. The list must not contain text characters like '\\n' and of the sort.\n",
        "Helpful Answer:\n",
        "\"\"\"\n",
        "\n",
        "answer_character_list = map_reduce_text(\n",
        "    clean_dune,\n",
        "    map_template_characters,\n",
        "    reduce_template_characters\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fHJMFqQzFArn",
        "outputId": "564537d6-a1d2-45e4-a758-a367cf244a14"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain_google_genai.chat_models:Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
            "WARNING:langchain_google_genai.chat_models:Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
            "WARNING:langchain_google_genai.chat_models:Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
            "WARNING:langchain_google_genai.chat_models:Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
            "WARNING:langchain_google_genai.chat_models:Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 16.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
            "WARNING:langchain_google_genai.chat_models:Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 32.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "answer_character_list"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "id": "q9ierRM-ClPw",
        "outputId": "7149dffb-b00a-4275-f751-72579a186e37"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"```python\\ncharacters_name = ['Irulan', 'Paul', 'Jessica', 'Stilgar', 'Chani', 'Harkonnen soldier', 'Harkonnen commander', 'Rabban', 'Fremen sentinel', 'sentinel leader', 'Jamis', 'Shishakli', 'old watermaster', 'Fedaykin fighter', 'Usul', 'Muad‚ÄôDib', 'Baron Harkonnen', 'male Fedaykin fighter', 'nun', 'Emperor', 'Reverend Mother Mohiam', 'Feyd-Rautha Harkonnen', 'Feyd-Rautha', 'weapon master', 'attendant', 'slave master', 'Lanville', 'Lady Margot Fenring', 'Bene Gesserit sister 1', 'Bene Gesserit sister 2', 'gladiator arena announcer', 'Baron Harkonnen', 'Rabban', 'Gurney', 'Maker Keeper', 'Alia', 'Rabban Harkonnen', 'Paul Muad‚ÄôDib Atreides', 'Bashar']\\n```\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 251
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import plotly.express as px\n",
        "from itertools import count\n",
        "import ast\n",
        "import re\n",
        "import numpy as np\n",
        "\n",
        "def plot_characters(answer_character_list):\n",
        "  # Clear answer\n",
        "  characters_list = re.findall(r\"'(.*?)'\", answer_character_list)\n",
        "\n",
        "  # distil the characters output\n",
        "  \"\"\"\n",
        "  Recomendaci√≥n, utilizar un diccionario para ordenar los personajes\n",
        "  \"\"\"\n",
        "  count_characters = {}\n",
        "  for character in characters_list:\n",
        "    pattern = rf'\\[{re.escape(character)}\\]'\n",
        "    matches = re.findall(pattern, clean_dune)\n",
        "    count_characters[character] = len(matches)\n",
        "\n",
        "  # Create dataframe\n",
        "  \"\"\"\n",
        "  De diccionario a DataFrame\n",
        "  \"\"\"\n",
        "  df_characters = pd.DataFrame(list(count_characters.items()), columns=['Personaje', 'Frecuencia en el script'])\n",
        "  df_characters = df_characters.sort_values(by='Frecuencia en el script', ascending=False)\n",
        "\n",
        "  # Graficar datos\n",
        "\n",
        "  fig = px.bar(\n",
        "      df_characters,\n",
        "      x='Personaje',\n",
        "      y='Frecuencia en el script',\n",
        "      title='Personajes de la pel√≠cula y su frecuencia',\n",
        "      template='plotly_white'\n",
        "  )\n",
        "  fig.show()\n",
        "\n",
        "  #Retornar los personajes\n",
        "  return df_characters[['Personaje']].reset_index(drop=True)"
      ],
      "metadata": {
        "id": "hJQ-RPYJKOKU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = plot_characters(answer_character_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "8QKbjLVI0y9t",
        "outputId": "9ae349e4-7247-4285-85ee-e3c61eba599a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.24.1.min.js\"></script>                <div id=\"da597d62-0118-454d-9d29-93bfbf71238f\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"da597d62-0118-454d-9d29-93bfbf71238f\")) {                    Plotly.newPlot(                        \"da597d62-0118-454d-9d29-93bfbf71238f\",                        [{\"alignmentgroup\":\"True\",\"hovertemplate\":\"Personaje=%{x}\\u003cbr\\u003eFrecuencia en el script=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"\",\"marker\":{\"color\":\"#636efa\",\"pattern\":{\"shape\":\"\"}},\"name\":\"\",\"offsetgroup\":\"\",\"orientation\":\"v\",\"showlegend\":false,\"textposition\":\"auto\",\"x\":[\"Paul\",\"Chani\",\"Stilgar\",\"Jessica\",\"Feyd-Rautha\",\"Gurney\",\"Rabban\",\"Lady Margot Fenring\",\"Baron Harkonnen\",\"Harkonnen commander\",\"Shishakli\",\"Irulan\",\"Emperor\",\"Harkonnen soldier\",\"Reverend Mother Mohiam\",\"Alia\",\"Bashar\",\"Fedaykin fighter\",\"slave master\",\"Bene Gesserit sister 1\",\"Jamis\",\"Bene Gesserit sister 2\",\"Lanville\",\"Usul\",\"nun\",\"sentinel leader\",\"Fremen sentinel\",\"old watermaster\",\"Muad‚ÄôDib\",\"male Fedaykin fighter\",\"weapon master\",\"attendant\",\"Feyd-Rautha Harkonnen\",\"Maker Keeper\",\"gladiator arena announcer\",\"Rabban Harkonnen\",\"Paul Muad‚ÄôDib Atreides\"],\"xaxis\":\"x\",\"y\":[73,42,35,32,15,14,9,7,6,5,5,4,4,4,3,2,2,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0],\"yaxis\":\"y\",\"type\":\"bar\"}],                        {\"template\":{\"data\":{\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"white\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"#C8D4E3\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"white\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"radialaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"yaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"zaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"caxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Personaje\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Frecuencia en el script\"}},\"legend\":{\"tracegroupgap\":0},\"title\":{\"text\":\"Personajes de la pel√≠cula y su frecuencia\"},\"barmode\":\"relative\"},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('da597d62-0118-454d-9d29-93bfbf71238f');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **1.2.4 Actores principales (0.75 puntos)**\n",
        "\n",
        "Importante saber que el script **no** maneja informaci√≥n de los actores, por ello, es importante que nuestra LLM tenga acceso a internet, de manera de poder realizar b√∫squedas que nos ayuden a completar la informaci√≥n consultada.\n",
        "\n",
        "Para esto, utilizaremos agentes combinados con react para realzar la consulta y asegurarnos de que la respuesta es correcta."
      ],
      "metadata": {
        "id": "2G2dx0XoLis4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.agents import load_tools\n",
        "from langchain.agents import AgentType, initialize_agent"
      ],
      "metadata": {
        "id": "A9CHzsLDKPeL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Key para realizar una busqueda\n",
        "os.environ[\"SERPER_API_KEY\"] = 'd63e62662ef63eb9e44ab133d191f7a99a0024a3'"
      ],
      "metadata": {
        "id": "4ZSclMoFMGSO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "personajes = df.Personaje.to_list()"
      ],
      "metadata": {
        "id": "r6U6E49hThHS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_actors_and_age(character):\n",
        "\n",
        "  # Inicializar tools y agente.\n",
        "  tools = load_tools([\"google-serper\", \"llm-math\"], llm=llm)\n",
        "  agent = initialize_agent(tools, llm, agent=\"zero-shot-react-description\", verbose=True)\n",
        "\n",
        "  # Crear template de query\n",
        "  query_template = \"\"\"  Here is a list of characters from the movie {movie}: {characters}\n",
        "    For each character, find the name of the actor who played them and their current age plus one year (age + 1).\n",
        "    Provide the results in the following format:\n",
        "    Character: [character name], Actor: [actor name], Age+1: [actor age + 1].\n",
        "  \"\"\"\n",
        "  # Crear prompt y usar agente para la b√∫squeda.\n",
        "  reduce_prompt = PromptTemplate.from_template(query_template)\n",
        "\n",
        "  # Retornar Nombre y Edad + 1\n",
        "  reduce_prompt = PromptTemplate.from_template(query_template)\n",
        "  agent_templated = reduce_prompt | agent\n",
        "  agent_answer = agent_templated.invoke(\n",
        "      {\n",
        "          'movie': script1_title,\n",
        "          'characters': personajes\n",
        "      }\n",
        "  )\n",
        "  return agent_answer['output']"
      ],
      "metadata": {
        "id": "sbGuaD6PMMA5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_actors_and_age(personajes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 654
        },
        "id": "TF00YUnpPx09",
        "outputId": "29b4c6cd-348b-4351-9173-6ee482519be3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mThought: I need to find the actors and their ages for each character in the list. I can use Google Search to find this information.\n",
            "Action: google_serper\n",
            "Action Input: \"Dune Part Two cast and age\"\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3mScience fiction epic that serves as a continuation of 2021's Dune. Paul Atreides reunites with the Fremen as he seeks revenge against those who destroyed his ... Timoth√©e Chalamet ¬∑ Paul Atreides ; Zendaya ¬∑ Chani ; Rebecca Ferguson ¬∑ Jessica ; Javier Bardem ¬∑ Stilgar ; Josh Brolin ¬∑ Gurney Halleck. Your guide to the full cast and characters of Dune: Part Two which is led by Timoth√©e Chalamet as Paul Atreides and Zendaya as Chani ... Dune: Part Two (2024) cast and crew credits, including actors, actresses, directors, writers and more. Missing: age | Show results with:age. Share on Social Media ¬∑ Timoth√©e Chalamet as Paul Atreides ¬∑ Zendaya as Chani ¬∑ Javier Bardem as Stilgar ¬∑ Rebecca Ferguson as Lady Jessica ¬∑ Josh ... The Dune 2 cast features both returning actors from the first film, like Timoth√©e Chalamet and Zendaya, and newcomers like Florence Pugh. Timoth√©e Chalamet, Rebecca Ferguson, Josh Brolin, Stellan Skarsg√•rd, Dave Bautista, Zendaya, Charlotte Rampling, and Javier Bardem reprise their roles from the ... ... Age,Dune 2 Real Name,Dune 2 Real Life Actors,Dune 2024,Are,Real Name,Actors 2024 ... Duration: 2:58. Posted: Mar 11, 2024. 'Dune: Part Two' Cast and Character Guide: Who Plays Who? ; Zendaya as Chani. Timoth√©e Chalamet, Rebecca Ferguson, Josh Brolin, Stellan Skarsg√•rd, Dave Bautista, Stephen McKinley Henderson, Zendaya, Charlotte Rampling, and ...\u001b[0m\n",
            "Thought:"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-322-6f4b890d6f23>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_actors_and_age\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpersonajes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-321-1cc00107339a>\u001b[0m in \u001b[0;36mget_actors_and_age\u001b[0;34m(character)\u001b[0m\n\u001b[1;32m     17\u001b[0m   \u001b[0mreduce_prompt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPromptTemplate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_template\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery_template\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m   \u001b[0magent_templated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreduce_prompt\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m   agent_answer = agent_templated.invoke(\n\u001b[0m\u001b[1;32m     20\u001b[0m       {\n\u001b[1;32m     21\u001b[0m           \u001b[0;34m'movie'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mscript1_title\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/runnables/base.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   2505\u001b[0m                     \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2506\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2507\u001b[0;31m                     \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2508\u001b[0m         \u001b[0;31m# finish the root run\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2509\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    164\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m             \u001b[0mrun_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_chain_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m         \u001b[0mrun_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_chain_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    154\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m             outputs = (\n\u001b[0;32m--> 156\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mnew_arg_supported\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m                 \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/agents/agent.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs, run_manager)\u001b[0m\n\u001b[1;32m   1431\u001b[0m         \u001b[0;31m# We now enter the agent loop (until it returns something).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1432\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_continue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime_elapsed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1433\u001b[0;31m             next_step_output = self._take_next_step(\n\u001b[0m\u001b[1;32m   1434\u001b[0m                 \u001b[0mname_to_tool_map\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1435\u001b[0m                 \u001b[0mcolor_mapping\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/agents/agent.py\u001b[0m in \u001b[0;36m_take_next_step\u001b[0;34m(self, name_to_tool_map, color_mapping, inputs, intermediate_steps, run_manager)\u001b[0m\n\u001b[1;32m   1137\u001b[0m     ) -> Union[AgentFinish, List[Tuple[AgentAction, str]]]:\n\u001b[1;32m   1138\u001b[0m         return self._consume_next_step(\n\u001b[0;32m-> 1139\u001b[0;31m             [\n\u001b[0m\u001b[1;32m   1140\u001b[0m                 \u001b[0ma\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1141\u001b[0m                 for a in self._iter_next_step(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/agents/agent.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1137\u001b[0m     ) -> Union[AgentFinish, List[Tuple[AgentAction, str]]]:\n\u001b[1;32m   1138\u001b[0m         return self._consume_next_step(\n\u001b[0;32m-> 1139\u001b[0;31m             [\n\u001b[0m\u001b[1;32m   1140\u001b[0m                 \u001b[0ma\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1141\u001b[0m                 for a in self._iter_next_step(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/agents/agent.py\u001b[0m in \u001b[0;36m_iter_next_step\u001b[0;34m(self, name_to_tool_map, color_mapping, inputs, intermediate_steps, run_manager)\u001b[0m\n\u001b[1;32m   1165\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1166\u001b[0m             \u001b[0;31m# Call the LLM to see what to do.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1167\u001b[0;31m             output = self.agent.plan(\n\u001b[0m\u001b[1;32m   1168\u001b[0m                 \u001b[0mintermediate_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1169\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_child\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mrun_manager\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/agents/agent.py\u001b[0m in \u001b[0;36mplan\u001b[0;34m(self, intermediate_steps, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    729\u001b[0m         \"\"\"\n\u001b[1;32m    730\u001b[0m         \u001b[0mfull_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_full_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mintermediate_steps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 731\u001b[0;31m         \u001b[0mfull_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mllm_chain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfull_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    732\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_parser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfull_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    733\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    315\u001b[0m                 \u001b[0mcompletion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mllm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madjective\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"funny\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m         \"\"\"\n\u001b[0;32m--> 317\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_key\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    318\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m     \u001b[0;32masync\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mapredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mCallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py\u001b[0m in \u001b[0;36mwarning_emitting_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    166\u001b[0m                 \u001b[0mwarned\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m                 \u001b[0memit_warning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 168\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    169\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m         \u001b[0;32masync\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mawarning_emitting_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, run_name, include_run_info)\u001b[0m\n\u001b[1;32m    381\u001b[0m         }\n\u001b[1;32m    382\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 383\u001b[0;31m         return self.invoke(\n\u001b[0m\u001b[1;32m    384\u001b[0m             \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m             \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRunnableConfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    164\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m             \u001b[0mrun_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_chain_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m         \u001b[0mrun_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_chain_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    154\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m             outputs = (\n\u001b[0;32m--> 156\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mnew_arg_supported\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m                 \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs, run_manager)\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0mrun_manager\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mCallbackManagerForChainRun\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m     ) -> Dict[str, str]:\n\u001b[0;32m--> 127\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, input_list, run_manager)\u001b[0m\n\u001b[1;32m    137\u001b[0m         \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_child\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mrun_manager\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mllm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBaseLanguageModel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m             return self.llm.generate_prompt(\n\u001b[0m\u001b[1;32m    140\u001b[0m                 \u001b[0mprompts\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m                 \u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\u001b[0m in \u001b[0;36mgenerate_prompt\u001b[0;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    675\u001b[0m     ) -> LLMResult:\n\u001b[1;32m    676\u001b[0m         \u001b[0mprompt_messages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_messages\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprompts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 677\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt_messages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    678\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    679\u001b[0m     async def agenerate_prompt(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[1;32m    532\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mrun_managers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m                     \u001b[0mrun_managers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_llm_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mLLMResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 534\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    535\u001b[0m         flattened_outputs = [\n\u001b[1;32m    536\u001b[0m             \u001b[0mLLMResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerations\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mllm_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mllm_output\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[list-item]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[1;32m    522\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m                 results.append(\n\u001b[0;32m--> 524\u001b[0;31m                     self._generate_with_cache(\n\u001b[0m\u001b[1;32m    525\u001b[0m                         \u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    526\u001b[0m                         \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\u001b[0m in \u001b[0;36m_generate_with_cache\u001b[0;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    747\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    748\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_generate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"run_manager\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 749\u001b[0;31m                 result = self._generate(\n\u001b[0m\u001b[1;32m    750\u001b[0m                     \u001b[0mmessages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_manager\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    751\u001b[0m                 )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_google_genai/chat_models.py\u001b[0m in \u001b[0;36m_generate\u001b[0;34m(self, messages, stop, run_manager, tools, functions, safety_settings, tool_config, generation_config, **kwargs)\u001b[0m\n\u001b[1;32m    765\u001b[0m             \u001b[0mgeneration_config\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgeneration_config\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m         )\n\u001b[0;32m--> 767\u001b[0;31m         response: GenerateContentResponse = _chat_with_retry(\n\u001b[0m\u001b[1;32m    768\u001b[0m             \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    769\u001b[0m             \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_google_genai/chat_models.py\u001b[0m in \u001b[0;36m_chat_with_retry\u001b[0;34m(generation_method, **kwargs)\u001b[0m\n\u001b[1;32m    194\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_chat_with_retry\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tenacity/__init__.py\u001b[0m in \u001b[0;36mwrapped_f\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    330\u001b[0m         )\n\u001b[1;32m    331\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mwrapped_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mretry_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mWrappedFn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tenacity/__init__.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    467\u001b[0m         \u001b[0mretry_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRetryCallState\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretry_object\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    468\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 469\u001b[0;31m             \u001b[0mdo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretry_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretry_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    470\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDoAttempt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    471\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tenacity/__init__.py\u001b[0m in \u001b[0;36miter\u001b[0;34m(self, retry_state)\u001b[0m\n\u001b[1;32m    368\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0maction\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactions\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 370\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretry_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    371\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    372\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tenacity/__init__.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(rs)\u001b[0m\n\u001b[1;32m    390\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_post_retry_check_actions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretry_state\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"RetryCallState\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_explicit_retry\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretry_run_result\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 392\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_add_action_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mrs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mrs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutcome\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    393\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    449\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mCancelledError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mFINISHED\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 451\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/concurrent/futures/_base.py\u001b[0m in \u001b[0;36m__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    401\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 403\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    404\u001b[0m             \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    405\u001b[0m                 \u001b[0;31m# Break a reference cycle with the exception in self._exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tenacity/__init__.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    470\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDoAttempt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    471\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 472\u001b[0;31m                     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    473\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# noqa: B902\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m                     \u001b[0mretry_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[arg-type]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_google_genai/chat_models.py\u001b[0m in \u001b[0;36m_chat_with_retry\u001b[0;34m(**kwargs)\u001b[0m\n\u001b[1;32m    176\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_chat_with_retry\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mgeneration_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m         \u001b[0;31m# Do not retry for these errors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFailedPrecondition\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\u001b[0m in \u001b[0;36mgenerate_content\u001b[0;34m(self, request, model, contents, retry, timeout, metadata)\u001b[0m\n\u001b[1;32m    825\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    826\u001b[0m         \u001b[0;31m# Send the request.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 827\u001b[0;31m         response = rpc(\n\u001b[0m\u001b[1;32m    828\u001b[0m             \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    829\u001b[0m             \u001b[0mretry\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretry\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, timeout, retry, *args, **kwargs)\u001b[0m\n\u001b[1;32m    111\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"metadata\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/api_core/retry.py\u001b[0m in \u001b[0;36mretry_wrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    347\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maximum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmultiplier\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_multiplier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m             )\n\u001b[0;32m--> 349\u001b[0;31m             return retry_target(\n\u001b[0m\u001b[1;32m    350\u001b[0m                 \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_predicate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/api_core/retry.py\u001b[0m in \u001b[0;36mretry_target\u001b[0;34m(target, predicate, sleep_generator, timeout, on_error, **kwargs)\u001b[0m\n\u001b[1;32m    189\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0msleep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msleep_generator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 191\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m         \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\u001b[0m in \u001b[0;36mfunc_with_timeout\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    118\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"timeout\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtime_since_first_attempt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc_with_timeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\u001b[0m in \u001b[0;36merror_remapped_callable\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0merror_remapped_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcallable_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mgrpc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRpcError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_grpc_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/grpc/_channel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[0m\n\u001b[1;32m   1176\u001b[0m             \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1177\u001b[0m             \u001b[0mcall\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1178\u001b[0;31m         \u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_blocking\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1179\u001b[0m             \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcredentials\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwait_for_ready\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompression\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/grpc/_channel.py\u001b[0m in \u001b[0;36m_blocking\u001b[0;34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[0m\n\u001b[1;32m   1160\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_registered_call_handle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1161\u001b[0m             )\n\u001b[0;32m-> 1162\u001b[0;31m             \u001b[0mevent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1163\u001b[0m             \u001b[0m_handle_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_response_deserializer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1164\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32msrc/python/grpcio/grpc/_cython/_cygrpc/channel.pyx.pxi\u001b[0m in \u001b[0;36mgrpc._cython.cygrpc.SegregatedCall.next_event\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32msrc/python/grpcio/grpc/_cython/_cygrpc/channel.pyx.pxi\u001b[0m in \u001b[0;36mgrpc._cython.cygrpc._next_call_event\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32msrc/python/grpcio/grpc/_cython/_cygrpc/channel.pyx.pxi\u001b[0m in \u001b[0;36mgrpc._cython.cygrpc._next_call_event\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32msrc/python/grpcio/grpc/_cython/_cygrpc/completion_queue.pyx.pxi\u001b[0m in \u001b[0;36mgrpc._cython.cygrpc._latent_event\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32msrc/python/grpcio/grpc/_cython/_cygrpc/completion_queue.pyx.pxi\u001b[0m in \u001b[0;36mgrpc._cython.cygrpc._internal_latent_event\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32msrc/python/grpcio/grpc/_cython/_cygrpc/completion_queue.pyx.pxi\u001b[0m in \u001b[0;36mgrpc._cython.cygrpc._next\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Explicar metodolog√≠a utilizada**\n",
        "\n",
        ":"
      ],
      "metadata": {
        "id": "Kpf9H61qMxal"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **1.2.5 Personajes Stats (0.5 puntos)**\n",
        "\n",
        "Esta parte es similar al punto 2. La clave esta en crear un buen prompting que nos permita generar las estad√≠sticas basandonos en una b√∫squeda por map/reduce.\n",
        "\n",
        "Tras la b√∫squeda, la idea es tener una funci√≥n de Python que nos permita generar el gr√°fico deseado y tener el resumen de los personajes.\n"
      ],
      "metadata": {
        "id": "MtQqA40sM09E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "def map_reduce_text(script, character):\n",
        "  # Map\n",
        "  map_template = \"\"\"\n",
        "  Crear template, utilizar las palabras claves:\n",
        "  Intelligence, Charisma, Strength, Wisdom, Emotional Resilience and Creativity.\n",
        "  \"\"\"\n",
        "\n",
        "  # crear prompt y cadena\n",
        "  map_template += template_complemt\n",
        "  map_prompt = # ...\n",
        "  map_chain = # ...\n",
        "\n",
        "  # Reduce\n",
        "  reduce_template = \"\"\"\n",
        "  Crear prompt de reducci√≥n.\n",
        "  Reducir, dado el perfil, en escala del 1 al 10 las cualidades mencionadas\n",
        "  \"\"\"\n",
        "  reduce_prompt = # ...\n",
        "  reduce_chain = # ...\n",
        "\n",
        "  # Reduce\n",
        "  \"\"\"\n",
        "  Reducir y combinar los documentos con un m√°ximo de 4000 tokens\n",
        "  \"\"\"\n",
        "\n",
        "  # Map/Reduce\n",
        "  \"\"\"\n",
        "  Uilizar MapReduceDocumentsChain\n",
        "  \"\"\"\n",
        "\n",
        "\n",
        "  # Text splitter\n",
        "  \"\"\"\n",
        "  Usar RecursiveCharacterTextSplitter\n",
        "  \"\"\"\n",
        "\n",
        "  result = map_reduce_chain.invoke(split_script)\n",
        "  return result[\"output_text\"]\n",
        "\n",
        "\n",
        "# Formato del perfil\n",
        "def format_profile(answer_character_profile):\n",
        "  \"\"\"\n",
        "  Crear un json con las caracteristicas y que retorne\n",
        "  (final_profile, stats) del personaje\n",
        "  \"\"\"\n",
        "  return (final_profile, stats)\n"
      ],
      "metadata": {
        "id": "ha1zVrtkNaF-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Escriba su respuesta ac√°"
      ],
      "metadata": {
        "id": "T_wwMRm7PbXC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_profile, stats = format_profile(answer_character_profile)"
      ],
      "metadata": {
        "id": "0oduYAOZPaL_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(final_profile)"
      ],
      "metadata": {
        "id": "eOQ8yMG5PhGT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Funci√≥n para gr√°ficar stats. No Tocar.\n",
        "\n",
        "import plotly.graph_objects as go\n",
        "import numpy as np\n",
        "\n",
        "def plot_stats(stats, character_name=\"Paul Atreides\"):\n",
        "    base_stats = [\n",
        "        \"Intelligence\", \"Charisma\", \"Strength\",\n",
        "        \"Wisdom\", \"Emotional Resilience\", \"Creativity\"\n",
        "    ]\n",
        "    for stat in base_stats:\n",
        "        if stat not in stats:\n",
        "            stats[stat] = 0\n",
        "\n",
        "    labels = list(stats.keys())\n",
        "    stats_values = list(stats.values())\n",
        "    stats_values += stats_values[:1]\n",
        "    labels += labels[:1]\n",
        "\n",
        "    # Plotly figure\n",
        "    fig = go.Figure()\n",
        "    fig.add_trace(go.Scatterpolar(\n",
        "        r=stats_values,\n",
        "        theta=labels,\n",
        "        fill='toself',\n",
        "        name=character_name\n",
        "    ))\n",
        "\n",
        "    fig.update_layout(\n",
        "        polar=dict(\n",
        "            radialaxis=dict(\n",
        "                visible=True,\n",
        "                range=[0, max(stats_values)]\n",
        "            )\n",
        "        ),\n",
        "        showlegend=False,\n",
        "        title=character_name\n",
        "    )\n",
        "\n",
        "    return fig\n",
        "\n",
        "fig = plot_stats(stats)"
      ],
      "metadata": {
        "id": "IXAHPyRSP6HY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Comentar (0.25 puntos)**\n",
        "Explicar metodolog√≠a y secuencia l√≥gica de cada una de las respuestas. Adem√°s responda:\n",
        "\n",
        "* ¬øQu√© otras tareas se podr√≠a realizar? De dos ejemplos con la metodolog√≠a asociada.\n",
        "\n",
        "* ¬øCual es la importancia de los prompt y como estos afectan al desempe√±o de los LLM?\n",
        "\n",
        "* ¬øAlguna de sus respuestas fue una 'alucinaci√≥n'? ¬øPor qu√© sucede esto?"
      ],
      "metadata": {
        "id": "_APhHBPXQXTX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **2. Reinforcement Learning (2.0 puntos)**\n",
        "\n",
        "En esta secci√≥n van a usar m√©todos de RL para resolver dos problemas interesantes: `Blackjack` y `LunarLander`."
      ],
      "metadata": {
        "id": "0hmHHQ9BuyAG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -qqq gymnasium stable_baselines3\n",
        "!pip install -qqq swig\n",
        "!pip install -qqq gymnasium[box2d]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gOcejYb6uzOO",
        "outputId": "72dfe85d-6629-4c3f-d6a0-0d1952da5c16"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m953.9/953.9 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m182.3/182.3 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m72.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m21.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m374.4/374.4 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for box2d-py (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **2.1 Blackjack (1.0 puntos)**\n",
        "\n",
        "<p align=\"center\">\n",
        "  <img src=\"https://www.recreoviral.com/wp-content/uploads/2016/08/s3.amazonaws.com-Math.gif\"\n",
        "\" width=\"400\">\n",
        "</p>\n",
        "\n",
        "Joaqu√≠n es fan√°tico del Blackjack, por lo que en esta subsecci√≥n implementar√°n m√©todos de RL y as√≠ generar una estrategia para que pueda ~~ir al casino a  hacerse millonario~~ aprender a resolver problemas mediante RL.\n",
        "\n",
        "Comencemos primero preparando el ambiente. El siguiente bloque de c√≥digo transforma las observaciones del ambiente a `np.array`:\n"
      ],
      "metadata": {
        "id": "qBPet_Mq8dX9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gymnasium as gym\n",
        "from gymnasium.spaces import MultiDiscrete\n",
        "import numpy as np\n",
        "\n",
        "class FlattenObservation(gym.ObservationWrapper):\n",
        "    def __init__(self, env):\n",
        "        super(FlattenObservation, self).__init__(env)\n",
        "        self.observation_space = MultiDiscrete(np.array([32, 11, 2]))\n",
        "\n",
        "    def observation(self, observation):\n",
        "        return np.array(observation).flatten()\n",
        "\n",
        "# Create and wrap the environment\n",
        "env = gym.make(\"Blackjack-v1\")\n",
        "env = FlattenObservation(env)"
      ],
      "metadata": {
        "id": "LpZ8bBKk9ZlU"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **2.1.1 Descripci√≥n de MDP (0.2 puntos)**\n",
        "\n",
        "Entregue una breve descripci√≥n sobre el ambiente [Blackjack](https://gymnasium.farama.org/environments/toy_text/blackjack/) y su formulaci√≥n en MDP, distinguiendo de forma clara y concisa los estados, acciones y recompensas."
      ],
      "metadata": {
        "id": "ZJ6J1_-Y9nHO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Estados**\n",
        "1. Suma actual del jugador (entero)\n",
        "2. Valor de la carta visible del crupier (1-10, donde 1 representa un as)\n",
        "3. Si el jugador tiene un as usable (0 o 1)\n",
        "\n",
        "**Acciones:** El espacio de acciones es discreto con dos posibilidades\n",
        "- 0: Plantarse (dejar de recibir cartas)\n",
        "- 1: Pedir (solicitar una carta adicional)\n",
        "\n",
        "**Recompensas:** La funci√≥n de recompensa se define como\n",
        "- Ganar: +1\n",
        "- Perder: -1\n",
        "- Empate: 0\n",
        "- Ganar con un blackjack natural:\n",
        "  - +1.5 si natural=True\n",
        "  - +1 si natural=False"
      ],
      "metadata": {
        "id": "N0nNGxfAW_SZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **2.1.2 Generando un Baseline (0.2 puntos)**\n",
        "\n",
        "* Simule un escenario en donde se escojan acciones aleatorias. Repita esta\n",
        "simulaci√≥n 5000 veces y reporte el promedio y desviaci√≥n de las recompensas.\n",
        "* ¬øC√≥mo calificar√≠a el performance de esta pol√≠tica?\n",
        "* ¬øC√≥mo podr√≠a interpretar las recompensas obtenidas?"
      ],
      "metadata": {
        "id": "pmcX6bRC9agQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "episodes = 5000\n",
        "rewards = np.zeros(episodes)\n",
        "\n",
        "for episode in range(episodes):\n",
        "    obs, info = env.reset()\n",
        "    done = False\n",
        "\n",
        "    while not done:\n",
        "        action = env.action_space.sample()\n",
        "        obs, reward, done, _, info = env.step(action)\n",
        "\n",
        "    rewards[episode] = reward\n",
        "\n",
        "mean_reward = np.mean(rewards)\n",
        "std_reward = np.std(rewards)\n",
        "\n",
        "print(\"Mean reward:\", mean_reward)\n",
        "print(\"Standard deviation of rewards:\", std_reward)"
      ],
      "metadata": {
        "id": "RHCfKN7NGi1K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca0282d1-0a32-4807-f29d-92f7b7aca1a0"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean reward: -0.416\n",
            "Standard deviation of rewards: 0.8859706541415465\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**¬øC√≥mo calificar√≠a el performance de esta pol√≠tica?**\n",
        "\n",
        "La pol√≠tica de seleccionar acciones aleatorias en el Blackjack es **deficiente**. La recompensa promedio es negativa (-0.416), indicando p√©rdidas en promedio. La alta desviaci√≥n est√°ndar (0.886) muestra una gran variabilidad en las recompensas, esperable por las decisiones aleatorias.\n",
        "\n",
        "**¬øC√≥mo podr√≠a interpretar las recompensas obtenidas?**\n",
        "\n",
        "- **Recompensa promedio negativa** (-0.416): Esto significa que en promedio, el jugador termina perdiendo dinero, si uno sigue esta estrategia a largo plazo, es m√°s probable que termine con menos dinero del que empez√≥.\n",
        "- **Alta desviaci√≥n est√°ndar** (0.886): Esto muestra que las recompensas pueden variar mucho de una ronda a otra, a veces se puede ganar un poco m√°s, pero tambi√©n se puede perder bastante.\n"
      ],
      "metadata": {
        "id": "DSpJ8RUGXK_N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **2.1.3 Entrenamiento de modelo (0.2 puntos)**\n",
        "\n",
        "A partir del siguiente [enlace](https://stable-baselines3.readthedocs.io/en/master/guide/algos.html), escoja un modelo de `stable_baselines3` y entrenelo para resolver el ambiente `Blackjack`."
      ],
      "metadata": {
        "id": "LEO_dY4x_SJu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from stable_baselines3 import DQN\n",
        "from stable_baselines3.common.evaluation import evaluate_policy\n",
        "\n",
        "# Instantiate the agent\n",
        "model = DQN(\"MlpPolicy\", env, verbose=0)\n",
        "\n",
        "# Train the agent and display a progress bar\n",
        "model.learn(total_timesteps=int(2e5), progress_bar=True)"
      ],
      "metadata": {
        "id": "T0sp8XWsGg4P",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51,
          "referenced_widgets": [
            "b248ca1993694afd90401e60c7f4b53b",
            "8302ee2ded67482090417663d456adcf"
          ]
        },
        "outputId": "5b8ce387-28b3-4205-d50f-003edcb7308a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Output()"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b248ca1993694afd90401e60c7f4b53b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<stable_baselines3.dqn.dqn.DQN at 0x7850510132b0>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **2.1.4 Evaluaci√≥n de modelo (0.2 puntos)**\n",
        "\n",
        "* Repita el ejercicio 2.1.2 pero utilizando el modelo entrenado.\n",
        "* ¬øC√≥mo es el performance de su agente?\n",
        "* ¬øEs mejor o peor que el escenario baseline?"
      ],
      "metadata": {
        "id": "E-bpdb8wZID1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from stable_baselines3.common.evaluation import evaluate_policy\n",
        "\n",
        "mean_reward, std_reward = evaluate_policy(model, env, n_eval_episodes = 5_000)\n",
        "mean_reward, std_reward"
      ],
      "metadata": {
        "id": "S7jdmnTwGePD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3fda23f0-6630-4502-f7c5-d45ab79f356e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/stable_baselines3/common/evaluation.py:67: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(-0.0482, 0.9498824979964626)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para evaluar el desempe√±o del agente entrenado con el modelo de DQN en el problema de Blackjack, consideramos:\n",
        "\n",
        "- Promedio de recompensas: -0.0482\n",
        "- Desviaci√≥n est√°ndar de las recompensas: 0.9499\n",
        "\n",
        "**Desempe√±o del Agente**\n",
        "\n",
        "El agente entrenado muestra una recompensa promedio cercana a cero (-0.0482), indicando resultados neutros en promedio. Sin embargo, la alta desviaci√≥n est√°ndar (0.9498) revela que las recompensas var√≠an mucho entre simulaciones, debido a la naturaleza aleatoria del juego y las decisiones tomadas por el agente.\n",
        "\n",
        "**Comparaci√≥n con el Baseline**\n",
        "\n",
        "El agente entrenado muestra un desempe√±o ligeramente mejor, con un promedio de recompensas m√°s cercano a cero, lo que sugiere una estrategia m√°s informada que podr√≠a estar minimizando las p√©rdidas promedio. Sin embargo, la alta variabilidad en las recompensas indica que a√∫n hay espacio para mejorar la consistencia y la efectividad del agente en el juego de Blackjack.\n"
      ],
      "metadata": {
        "id": "abPF6hrpXdGB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **2.1.5 Estudio de acciones (0.2 puntos)**\n",
        "\n",
        "* Genere una funci√≥n que reciba un estado y retorne la accion del agente.\n",
        "* Luego, use esta funci√≥n para entregar la acci√≥n escogida frente a los siguientes escenarios:\n",
        "\n",
        "  * Suma de cartas del agente es 6, dealer muestra un 7, agente no tiene tiene un as\n",
        "  * Suma de cartas del agente es 19, dealer muestra un 3, agente tiene tiene un as\n",
        "\n",
        "* ¬øSon coherentes sus acciones con las reglas del juego?\n",
        "\n",
        "Hint: ¬øA que clase de python pertenecen los estados? Pruebe a usar el m√©todo `.reset` para saberlo."
      ],
      "metadata": {
        "id": "RO-EsAaPAYEm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "state = env.reset()\n",
        "type(state)"
      ],
      "metadata": {
        "id": "Lssdp7AvGaRh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "480a0f4c-6b04-4825-81fe-8cd689fde4fb"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tuple"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_action, prediction_info = model.predict(np.array([6, 7, 0]), deterministic=True)\n",
        "predicted_action"
      ],
      "metadata": {
        "id": "Px3-oWSeXka3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c5f423d-af40-4f5c-eb7f-00cb157e8886"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(1)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "El modelo predice array(1), lo que significa que el agente deber√≠a pedir otra carta."
      ],
      "metadata": {
        "id": "WgP3B5UNXmyV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_action, prediction_info = model.predict(np.array([19, 3, 1]), deterministic=True)\n",
        "predicted_action"
      ],
      "metadata": {
        "id": "L6Y4MazVXpJm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "47d7a8e7-9122-404d-93fc-a55ba96e58c1"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(0)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "El modelo predice array(0), lo que significa que el agente no deber√≠a pedir otra carta."
      ],
      "metadata": {
        "id": "2a89M56UXrRt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Recordemos las reglas b√°sicas para evaluar la coherencia:\n",
        "- El agente debe pedir otra carta si su suma de cartas es menor a 21 y no tiene un blackjack natural.\n",
        "- El agente puede *plantarse* si considera que su suma de cartas es lo suficientemente alta para ganar sin exceder 21. personalmente creo que desde 17 en adelante es weno :-)\n",
        "\n",
        "**Conclusiones**:\n",
        "- **Escenario 1**, el agente tiene una suma baja (6) frente a una carta fuerte del dealer (7), por lo tanto es coherente que el modelo sugiera pedir otra carta.\n",
        "- **Escenario 2**, el agente ya tiene una suma alta (19) y tiene un as, lo cual le da flexibilidad para decidir plantarse sin riesgo de pasarse de 21.\n",
        "\n",
        "Ambas acciones predichas por el modelo son coherentes con las reglas del juego seg√∫n los escenarios presentados."
      ],
      "metadata": {
        "id": "ZtTPM5fHXtBe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **2.2 LunarLander**\n",
        "\n",
        "<p align=\"center\">\n",
        "  <img src=\"https://i.redd.it/097t6tk29zf51.jpg\"\n",
        "\" width=\"400\">\n",
        "</p>\n",
        "\n",
        "Similar a la secci√≥n 2.1, en esta secci√≥n usted se encargar√° de implementar una gente de RL que pueda resolver el ambiente `LunarLander`.\n"
      ],
      "metadata": {
        "id": "SEqCTqqroh03"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **2.2.1 Descripci√≥n de MDP (0.2 puntos)**\n"
      ],
      "metadata": {
        "id": "sk5VJVppXh3N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Comencemos preparando el ambiente:"
      ],
      "metadata": {
        "id": "XvAVq1wQIjLc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gymnasium as gym\n",
        "env = gym.make(\"LunarLander-v2\", render_mode = \"rgb_array\", continuous = True) # notar el par√°metro continuous = True"
      ],
      "metadata": {
        "id": "Qb5PmadJIngR"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Entregue una breve descripci√≥n sobre el ambiente [LunarLander](https://gymnasium.farama.org/environments/box2d/lunar_lander/) y su formulaci√≥n en MDP, distinguiendo de forma clara y concisa los estados, acciones y recompensas.\n",
        "* ¬øComo se distinguen las acciones de este ambiente en comparaci√≥n a `Blackjack`?\n",
        "* En la preparaci√≥n del ambiente se especifica el par√°metro `continuous = True`. ¬øQue implicancias tiene esto sobre el ambiente?"
      ],
      "metadata": {
        "id": "LNERH-m8JYQb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "El MDP para Lunar Lander con `continuous=True` se puede describir de la siguiente manera:\n",
        "\n",
        "**Estados**: Vector de 8 dimensiones que contiene:\n",
        "  1. Coordenada x del m√≥dulo lunar\n",
        "  2. Coordenada y del m√≥dulo lunar\n",
        "  3. Velocidad lineal en x\n",
        "  4. Velocidad lineal en y\n",
        "  5. √Ångulo del m√≥dulo lunar\n",
        "  6. Velocidad angular\n",
        "  7. Booleano indicando si la pierna izquierda est√° en contacto con el suelo\n",
        "  8. Booleano indicando si la pierna derecha est√° en contacto con el suelo\n",
        "\n",
        "**Acciones**: Espacio continuo representado como `Box(-1, +1, (2,), dtype=np.float32)`:\n",
        "  - Primera coordenada: Controla el acelerador del motor principal (0-100% de potencia)\n",
        "  - Segunda coordenada: Controla los propulsores laterales\n",
        "\n",
        "**Recompensas**:\n",
        "  - Aumenta cuanto m√°s cerca est√° el m√≥dulo de la plataforma de aterrizaje\n",
        "  - Aumenta cuanto m√°s lento se mueve el m√≥dulo\n",
        "  - Disminuye cuanto m√°s inclinado est√° el m√≥dulo\n",
        "  - +10 puntos por cada pierna en contacto con el suelo\n",
        "  - -0.03 puntos por cada frame que un motor lateral est√° encendido\n",
        "  - -0.3 puntos por cada frame que el motor principal est√° encendido\n",
        "  - -100 puntos por estrellarse, +100 puntos por aterrizar con seguridad\n",
        "\n",
        "Las acciones en Lunar Lander son continuas, a diferencia de Blackjack donde eran discretas (pedir o plantarse). Esto permite un control m√°s preciso, pero tambi√©n hace que el espacio de acciones sea m√°s complejo."
      ],
      "metadata": {
        "id": "DbpGahPcHAje"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **2.2.2 Generando un Baseline (0.2 puntos)**\n",
        "\n",
        "* Simule un escenario en donde se escojan acciones aleatorias. Repita esta simulaci√≥n 10 veces y reporte el promedio y desviaci√≥n de las recompensas.\n",
        "* ¬øC√≥mo calificar√≠a el performance de esta pol√≠tica?\n",
        "\n",
        " Este performance es tremendamente pobre. Una recompensa constante de -100 sugiere que el m√≥dulo se est√° estrellando en cada episodio, lo cual es el peor resultado posible, pero esperado para acciones aleatorias en un ambiente tan complejo."
      ],
      "metadata": {
        "id": "YChodtNQwzG2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "episodes = 10\n",
        "rewards = np.zeros(episodes)\n",
        "\n",
        "for episode in range(episodes):\n",
        "    obs, info = env.reset()\n",
        "    done = False\n",
        "\n",
        "    while not done:\n",
        "        action = env.action_space.sample()\n",
        "        obs, reward, done, _, info = env.step(action)\n",
        "\n",
        "    rewards[episode] = reward\n",
        "\n",
        "mean_reward = np.mean(rewards)\n",
        "std_reward = np.std(rewards)\n",
        "\n",
        "print(\"Mean reward:\", mean_reward)\n",
        "print(\"Standard deviation of rewards:\", std_reward)\n"
      ],
      "metadata": {
        "id": "pNMT_GORIreW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a847eeaa-259c-43c6-e185-a5160d9e3dba"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean reward: -100.0\n",
            "Standard deviation of rewards: 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **2.2.3 Entrenamiento de modelo (0.2 puntos)**\n",
        "\n",
        "* A partir del siguiente [enlace](https://stable-baselines3.readthedocs.io/en/master/guide/algos.html), escoja un modelo de `stable_baselines3` y entrenelo para resolver el ambiente `LunarLander` **usando 10000 timesteps de entrenamiento**."
      ],
      "metadata": {
        "id": "hQrZVQflX_5f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from stable_baselines3 import SAC\n",
        "from stable_baselines3.common.evaluation import evaluate_policy\n",
        "\n",
        "# Instantiate the agent\n",
        "model = SAC(\"MlpPolicy\", env, verbose=0)\n",
        "\n",
        "# Train the agent and display a progress bar\n",
        "model.learn(total_timesteps=int(1e4), progress_bar=True)"
      ],
      "metadata": {
        "id": "Mg0epSnLKfy6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51,
          "referenced_widgets": [
            "bc0902664d034f73bf68eb28603a21a2",
            "9e6867520f7145b7bb513e2204466cec"
          ]
        },
        "outputId": "97e501d8-778a-48e1-f4b2-879f9ba2d003"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Output()"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bc0902664d034f73bf68eb28603a21a2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<stable_baselines3.sac.sac.SAC at 0x784edc6744f0>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **2.2.4 Evaluaci√≥n de modelo (0.2 puntos)**\n",
        "\n",
        "* Repita el ejercicio 2.2.2 pero utilizando el modelo entrenado.\n",
        "* ¬øC√≥mo es el performance de su agente? ¬øEs mejor o peor que el escenario baseline?"
      ],
      "metadata": {
        "id": "3z-oIUSrlAsY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from stable_baselines3.common.evaluation import evaluate_policy\n",
        "\n",
        "mean_reward, std_reward = evaluate_policy(model, env, n_eval_episodes = 50)\n",
        "mean_reward, std_reward"
      ],
      "metadata": {
        "id": "CWVY1a39KeRs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d8d6abf-4a58-4888-b023-9c04ad328493"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(-245.62136531946098, 163.17298812826402)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "El algoritmo SAC muestra un rendimiento promedio de -245.621, considerablemente peor que el baseline de -100 y un desempe√±o inconsistente con alta variabilidad (desviaci√≥n est√°ndar de 163.172 frente a 0 del baseline). Este resultado sugiere que el agente SAC podr√≠a estar tomando acciones poco inteligentes en lugar de mejorar la situaci√≥n, posiblemente debido a malos ajustes en los hiperpar√°metros."
      ],
      "metadata": {
        "id": "CZ2mxUdIX9rl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **2.2.5 Optimizaci√≥n de modelo (0.2 puntos)**\n",
        "\n",
        "* Repita los ejercicios 2.2.3 y 2.2.4 hasta obtener un nivel de recompensas promedio mayor a 50. Para esto, puede cambiar manualmente par√°metros como:\n",
        "  - `total_timesteps`\n",
        "  - `learning_rate`\n",
        "  - `batch_size`\n",
        "\n",
        "* Una vez optimizado el modelo, use la funci√≥n `export_gif` entregada para estudiar el comportamiento de su agente en la resoluci√≥n del ambiente, comente sobre sus resultados.\n",
        "\n",
        "* Adjunte el gif generado en su entrega. Si, adem√°s, adjuntan el gif en el markdown tendr√°n un bonus de 0.1."
      ],
      "metadata": {
        "id": "x6Xw4YHT3P5d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se demoro mucho en correo y nos explot√≥ el pc a ambas. NO CORRER, GRANADA! üöÄüî•üß®ü§Ø"
      ],
      "metadata": {
        "id": "xSK6fcHWb7iM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from stable_baselines3 import SAC\n",
        "from stable_baselines3.common.evaluation import evaluate_policy\n",
        "\n",
        "# Instantiate the agent\n",
        "model = SAC(\"MlpPolicy\", env, verbose=0)\n",
        "\n",
        "# Train the agent and display a progress bar\n",
        "model.learn(total_timesteps=int(2e5), progress_bar=True)\n",
        "\n",
        "mean_reward, std_reward = evaluate_policy(model, env, n_eval_episodes = 10)\n",
        "mean_reward, std_reward"
      ],
      "metadata": {
        "id": "w6nIf3C5YAd6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import imageio\n",
        "import numpy as np\n",
        "\n",
        "def export_gif(model, n = 5):\n",
        "  '''\n",
        "  funci√≥n que exporta a gif el comportamiento del agente en n episodios\n",
        "  '''\n",
        "  images = []\n",
        "  for episode in range(n):\n",
        "    obs = model.env.reset()\n",
        "    img = model.env.render()\n",
        "    done = False\n",
        "    while not done:\n",
        "      images.append(img)\n",
        "      action, _ = model.predict(obs)\n",
        "      obs, reward, done, info = model.env.step(action)\n",
        "      img = model.env.render(mode=\"rgb_array\")\n",
        "\n",
        "  imageio.mimsave(\"agent_performance.gif\", [np.array(img) for i, img in enumerate(images) if i%2 == 0], fps=29)"
      ],
      "metadata": {
        "id": "Ag-QIrmhLIY_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# escriba su respuesta ac√°"
      ],
      "metadata": {
        "id": "aItYF6sr6F_6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}