{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "b248ca1993694afd90401e60c7f4b53b": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_8302ee2ded67482090417663d456adcf",
            "msg_id": "",
            "outputs": [
              {
                "output_type": "display_data",
                "data": {
                  "text/plain": "\u001b[35m 100%\u001b[0m \u001b[38;2;249;38;114m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;2;249;38;114m╸\u001b[0m \u001b[32m199,955/200,000 \u001b[0m [ \u001b[33m0:06:29\u001b[0m < \u001b[36m0:00:01\u001b[0m , \u001b[31m501 it/s\u001b[0m ]\n",
                  "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080\"> 100%</span> <span style=\"color: #f92672; text-decoration-color: #f92672\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸</span> <span style=\"color: #008000; text-decoration-color: #008000\">199,955/200,000 </span> [ <span style=\"color: #808000; text-decoration-color: #808000\">0:06:29</span> &lt; <span style=\"color: #008080; text-decoration-color: #008080\">0:00:01</span> , <span style=\"color: #800000; text-decoration-color: #800000\">501 it/s</span> ]\n</pre>\n"
                },
                "metadata": {}
              }
            ]
          }
        },
        "8302ee2ded67482090417663d456adcf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bc0902664d034f73bf68eb28603a21a2": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_9e6867520f7145b7bb513e2204466cec",
            "msg_id": "",
            "outputs": [
              {
                "output_type": "display_data",
                "data": {
                  "text/plain": "\u001b[35m 100%\u001b[0m \u001b[38;2;249;38;114m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;2;249;38;114m╸\u001b[0m \u001b[32m9,999/10,000 \u001b[0m [ \u001b[33m0:02:44\u001b[0m < \u001b[36m0:00:01\u001b[0m , \u001b[31m61 it/s\u001b[0m ]\n",
                  "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080\"> 100%</span> <span style=\"color: #f92672; text-decoration-color: #f92672\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸</span> <span style=\"color: #008000; text-decoration-color: #008000\">9,999/10,000 </span> [ <span style=\"color: #808000; text-decoration-color: #808000\">0:02:44</span> &lt; <span style=\"color: #008080; text-decoration-color: #008080\">0:00:01</span> , <span style=\"color: #800000; text-decoration-color: #800000\">61 it/s</span> ]\n</pre>\n"
                },
                "metadata": {}
              }
            ]
          }
        },
        "9e6867520f7145b7bb513e2204466cec": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**<h1><center>Laboratorio 11: LLM y Agentes Autónomos 🤖</center></h1>**\n",
        "\n",
        "<center><strong>MDS7202: Laboratorio de Programación Científica para Ciencia de Datos</strong></center>"
      ],
      "metadata": {
        "id": "PyPTffTLug7i"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UD8X1uhGzAHq",
        "cell_id": "737a4540885f41acb34b9863a968b907",
        "deepnote_cell_type": "markdown"
      },
      "source": [
        "### **Cuerpo Docente:**\n",
        "\n",
        "- Profesor: Ignacio Meza, Sebastian Tinoco\n",
        "- Auxiliar: Catherine Benavides, Consuelo Rojas\n",
        "- Ayudante: Eduardo Moya, Nicolás Ojeda"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tXflExjqzAHr",
        "cell_id": "e4a6f26138654eb49ee963fb4c7ecf46",
        "deepnote_cell_type": "markdown"
      },
      "source": [
        "### **Equipo:**\n",
        "\n",
        "- Nombre de alumno 1: Melanie Peña Torres\n",
        "- Nombre de alumno 2: Valentina Rojas Osorio\n",
        "\n",
        "**SUPER IMPORTANTE** - notebooks sin nombre no serán revisados"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AD-V0bbZzAHr",
        "owner_user_id": "badcc427-fd3d-4615-9296-faa43ec69cfb",
        "cell_id": "7dd4aaebd4f44063aedbb47ea36349a5",
        "deepnote_cell_type": "markdown"
      },
      "source": [
        "### **Link de repositorio de GitHub:** [Link](https://github.com/melaniejalea/Laboratorios-MDS7202/tree/lab11)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EcnsiQMkzAHr",
        "cell_id": "abe08e51696a471e8cc8ac1fa4216f0b",
        "deepnote_cell_type": "markdown"
      },
      "source": [
        "### **Indice**\n",
        "\n",
        "1. [Temas a tratar](#Temas-a-tratar:)\n",
        "3. [Descripcción del laboratorio](#Descripción-del-laboratorio.)\n",
        "4. [Desarrollo](#Desarrollo)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6uBLPj1PzAHs",
        "cell_id": "0174e9377ebb43eaa0d12718db4c81ec",
        "deepnote_cell_type": "markdown"
      },
      "source": [
        "## **Temas a tratar**\n",
        "\n",
        "- Implementación de modelos de LLM y Reinforcement Learning.\n",
        "- Utilización e implementación de agentes.\n",
        "\n",
        "## **Reglas:**\n",
        "\n",
        "- **Grupos de 2 personas**\n",
        "- Fecha de entrega: 7 días desde la publicación, 3 días de atraso con 1 punto de descuento c/u.\n",
        "- Instrucciones del lab el viernes a las 16:15 en formato online. Asistencia no es obligatoria.\n",
        "- Prohibidas las copias. Cualquier intento de copia será debidamente penalizado con el reglamento de la escuela.\n",
        "- Tienen que subir el laboratorio a u-cursos y a su repositorio de github. Labs que no estén en u-cursos no serán revisados. Recuerden que el repositorio también tiene nota.\n",
        "- Cualquier duda fuera del horario de clases al foro. Mensajes al equipo docente serán respondidos por este medio.\n",
        "Pueden usar cualquer material del curso que estimen conveniente.\n",
        "\n",
        "### **Objetivos principales del laboratorio**\n",
        "\n",
        "- Generar un modelo LLM generativo interactivo.\n",
        "- Entrenar un modelo de Reinforce Learning.\n",
        "\n",
        "El laboratorio deberá ser desarrollado sin el uso indiscriminado de iteradores nativos de python (aka \"for\", \"while\"). La idea es que aprendan a exprimir al máximo las funciones optimizadas que nos entrega `pandas`, las cuales vale mencionar, son bastante más eficientes que los iteradores nativos sobre DataFrames."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **1. Large Language Models (4.0 puntos)**"
      ],
      "metadata": {
        "id": "Is4P4NDMurx6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p align=\"center\">\n",
        "  <img src=\"https://trestristescriticos.com/wp-content/uploads/2021/07/telefono-gratuito-cinesur.jpg\" width=\"350\">\n",
        "</p>"
      ],
      "metadata": {
        "id": "tJ3yV96HwN75"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Joaquín no es un aficionado del cine, pero a principios de año, se propuso ver más peliculas para poder tener más temas de conversación con sus amigos y familia. Sin embargo, ya es junio y Joaquín no ha visto ninguna pelicula nueva o relevante de las que tenía en su lista y su reunión familiar bi-anual se acerca y necesita la mayor información que pueda recopilar de dichas peliculas sin tener que verlas.\n",
        "\n",
        "Para esto, usted con su compañerx, tendrá que crear una aplicación utilizando LangChain.\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "kB8z1qrGww4o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Instalación de librerías**\n",
        "\n",
        "Para la creación de la aplicación, se utilizara un modelo de lenguaje (LLM) ofrecido gratuitamente por Google.\n",
        "\n",
        "Para ello, se utilizará la API de Gemini, por lo que si no tienen acceso, se pueden crear una cuenta en el siguiente [enlace a Google AI](https://ai.google.dev/). Ahí, ir a la pestaña superior y seleccione la opción que dice ``Gemini API``.\n",
        "\n",
        "<img src='https://gitlab.com/imezadelajara/datos_clase_7_mds7202/-/raw/main/misc_images/Screenshot_2024-06-13_at_12.42.32_PM.png' width='450' />\n",
        "\n",
        "Luego, seleccione el botón que dice ``Get API key in Google AI Studio`` y hacer click en ``Crear clave de API`` para generar la llave con la que se podrá consultar al modelo de lenguaje.\n",
        "\n",
        "<img src='https://gitlab.com/imezadelajara/datos_clase_7_mds7202/-/raw/main/misc_images/Screenshot_2024-06-13_at_12.45.10_PM.png?ref_type=heads' width='450' />\n",
        "\n",
        "**Importante:** Debido a las restricciones de esta API, lo ideal es utilizar la llave a la API de manera personal.\n",
        "\n",
        "\n",
        "Para mayor información sobre **LangChain**, pueden revisar la documentación en el [presente enlace](https://python.langchain.com/v0.2/docs/tutorials/summarization/ )."
      ],
      "metadata": {
        "id": "dOIeEP9Ey_lF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install langchain\n",
        "!pip install langchain_google_genai\n",
        "!pip install langchain-community\n",
        "!pip install langchain-experimental\n",
        "!pip install sentence-transformers\n",
        "!pip install faiss-cpu"
      ],
      "metadata": {
        "id": "LLbYWURudw2c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "82aJnnH0b0Oo"
      },
      "outputs": [],
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "import os\n",
        "\n",
        "os.environ[\"GOOGLE_API_KEY\"] = \"AIzaSyD904omnTtarZIyb9AAzjcbX8Gp1po7rMs\"\n",
        "llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **1.1 Carga y limpieza (0.5 puntos)**"
      ],
      "metadata": {
        "id": "kUgbzVtWUYq2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para iniciar su titanica tarea de enseñarle a Joaquín sobre las mejores peliculas del último tiempo, tiene que revisar los script de las siguientes 3 peliculas:\n",
        "* Dune 2\n",
        "* Under Paris\n",
        "* Joker\n",
        "\n",
        "Debe encontrar un patrón y obtener solamente el guión de las películas. Para ello se recomienda utilizar métodos de búsqueda y reemplazo que tienen los ``string`` en Python. Adicionalmente, puede usar filtros de expresiones regulares.\n",
        "\n",
        "Posterior a la limpieza de los guiones, debe considerar que el patrón se repite y es generalizable. ✅\n"
      ],
      "metadata": {
        "id": "6I10Li9a7nez"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Scripts de peliculas\n",
        "dune2_script=\"https://scrapsfromtheloft.com/movies/dune-part-two-2024-transcript/\"\n",
        "underparis_script=\"https://scrapsfromtheloft.com/movies/under-paris-2024-transcript/\"\n",
        "joker_script=\"https://scrapsfromtheloft.com/movies/joker-2019-transcript/\""
      ],
      "metadata": {
        "id": "HpYuwfO_F0pD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.document_loaders import WebBaseLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter"
      ],
      "metadata": {
        "id": "uqKYYPHhOCCF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_website_data(url):\n",
        "  '''\n",
        "  Escriba su código acá\n",
        "  '''\n",
        "  loader = WebBaseLoader(url)\n",
        "  docs = loader.load()\n",
        "  website_data = docs[0].page_content\n",
        "  return website_data"
      ],
      "metadata": {
        "id": "qax6fONAOCsC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "script_dune = load_website_data(dune2_script)\n",
        "script_underparis = load_website_data(underparis_script)\n",
        "script_joker = load_website_data(joker_script)"
      ],
      "metadata": {
        "id": "M5rvAJ5sOEmY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "script_dune[:500]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "id": "vgr_5nnbOU63",
        "outputId": "f237da3c-9c3e-4f41-bb7a-9c33a2e41afe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n\\n\\n\\n\\n\\n\\n\\nDune: Part Two (2024) | Transcript - Scraps from the loft\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\r\\n\\t\\tSkip to content\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nMOVIES\\n\\nMOVIE REVIEWS\\nMOVIE TRANSCRIPTS\\n\\n\\nTV SERIES\\n\\nTV SHOW TRANSCRIPTS\\n\\n\\nCOMEDY\\n\\nSTAND-UP COMEDY TRANSCRIPTS\\nGEORGE CARLIN\\nDAVE CHAPPELLE\\n\\n\\nINTERVIEWS\\n\\nPLAYBOY INTERVIEWS\\n\\n\\nMUSIC\\nHISTORY\\nBOOKS\\nOPINIONS\\n \\n\\n Menu\\n\\n\\nMOVIES\\n\\nMOVIE REVIEWS\\nMOVIE TRANSCRIPTS\\n\\n\\nTV SERIES\\n\\nTV SHOW TRANSCRIPTS\\n\\n\\nCOMEDY\\n\\nSTAND-UP C'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 163
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "script_underparis[:500]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "id": "PzS-UJxZQ1cd",
        "outputId": "59a84178-f840-428b-e7d1-372def28b550"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n\\n\\n\\n\\n\\n\\n\\nUnder Paris (2024) | Transcript - Scraps from the loft\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\r\\n\\t\\tSkip to content\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nMOVIES\\n\\nMOVIE REVIEWS\\nMOVIE TRANSCRIPTS\\n\\n\\nTV SERIES\\n\\nTV SHOW TRANSCRIPTS\\n\\n\\nCOMEDY\\n\\nSTAND-UP COMEDY TRANSCRIPTS\\nGEORGE CARLIN\\nDAVE CHAPPELLE\\n\\n\\nINTERVIEWS\\n\\nPLAYBOY INTERVIEWS\\n\\n\\nMUSIC\\nHISTORY\\nBOOKS\\nOPINIONS\\n \\n\\n Menu\\n\\n\\nMOVIES\\n\\nMOVIE REVIEWS\\nMOVIE TRANSCRIPTS\\n\\n\\nTV SERIES\\n\\nTV SHOW TRANSCRIPTS\\n\\n\\nCOMEDY\\n\\nSTAND-UP COMED'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "script_joker[:500]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "id": "DyeNURRMbRN6",
        "outputId": "4f38e3c9-feee-4911-c40d-dc74515dc98e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n\\n\\n\\n\\n\\n\\n\\nJoker (2019) | Transcript - Scraps from the loft\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\r\\n\\t\\tSkip to content\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nMOVIES\\n\\nMOVIE REVIEWS\\nMOVIE TRANSCRIPTS\\n\\n\\nTV SERIES\\n\\nTV SHOW TRANSCRIPTS\\n\\n\\nCOMEDY\\n\\nSTAND-UP COMEDY TRANSCRIPTS\\nGEORGE CARLIN\\nDAVE CHAPPELLE\\n\\n\\nINTERVIEWS\\n\\nPLAYBOY INTERVIEWS\\n\\n\\nMUSIC\\nHISTORY\\nBOOKS\\nOPINIONS\\n \\n\\n Menu\\n\\n\\nMOVIES\\n\\nMOVIE REVIEWS\\nMOVIE TRANSCRIPTS\\n\\n\\nTV SERIES\\n\\nTV SHOW TRANSCRIPTS\\n\\n\\nCOMEDY\\n\\nSTAND-UP COMEDY TRA'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_text_before_marker(text):\n",
        "    '''\n",
        "    Escriba su código acá\n",
        "    '''\n",
        "    '''\n",
        "    Notamos que hay caracteres como esto al usar la última función:\n",
        "    \\n[all laughing]\\n[speaking in Chakobsa]\n",
        "    y además hay que tener presente el * como token\n",
        "    de inicio, gracias NLP!\n",
        "    '''\n",
        "    start_markers = [\"* * *\", \"\\n[\"]\n",
        "    start_position = -1\n",
        "    for marker in start_markers:\n",
        "        position = text.find(marker)\n",
        "        if position != -1:\n",
        "            start_pos = position + len(marker)\n",
        "            break\n",
        "    if start_pos == -1:\n",
        "        start_pos = 0\n",
        "    text_out = text[start_pos:]\n",
        "    '''\n",
        "    Explorando los scripts usando la ultima función\n",
        "    notamos que el script termina alrededor del token de More dado que luego\n",
        "    lo que se tiene son anuncios para conseguir más scripts y rcibir anuncios\n",
        "    \\n[breathing heavily]\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nMore:\\n\\nDenis Villeneuve, Dune: Part Two, Movie Transcripts \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSHARE THIS ARTICLE \\n\\n\\n\\n\\n\\n\\n\\n \\n\\n\\n\\n\\n\\n\n",
        "     \\n\\n\\n\\n\\n\\n \\n\\n\\n\\n\\n\\n \\n\\n\\n\\n\\n\\n \\n\\n\\n\\n\\n\\n \\n\\n\\n\\n\\n\\n \\n\\n\\n\\n\\n\\n \\n\\n\\n\\n\\n\\n \\n\\n\\n\\n\\n\\n \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nLeave a Comment Cancel ReplyYour email address will not be published\n",
        "    '''\n",
        "    end_marker = \"\\n\\nMore:\\n\\n\"\n",
        "    end_position = text_out.find(end_marker)\n",
        "    if end_position != -1:\n",
        "        text_out = text_out[:end_position]\n",
        "    text_out = text_out.strip()\n",
        "    return text_out"
      ],
      "metadata": {
        "id": "XUfvpxPD8v5X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clean_dune = remove_text_before_marker(script_dune)\n",
        "clean_underparis = remove_text_before_marker(script_underparis)\n",
        "clean_joker = remove_text_before_marker(script_joker)"
      ],
      "metadata": {
        "id": "QIHssMSuOl1H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clean_dune[:500]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "c-wLQR8oPph6",
        "outputId": "1c8006bc-119d-4818-fb5e-f642b709e188"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'male voice in alien language] Power over Spice is power over all\\n[suspenseful music playing]\\n[Irulan] Imperial Diary. Year 10,191. Third comment. The battle for Arrakis took everyone by surprise. There were no witnesses.\\n[somber music playing]\\nThe Harkonnen operation was perpetrated overnight, without warning or declaration of war. By morning, the Atreides were no more. All died in the dark.\\nAnd the Emperor said… nothing. Since that night, my father has not been the same. Nor have I. His inactio'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "clean_underparis[:500]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "XkI1chH3Q6vB",
        "outputId": "e8dffee6-083b-4446-8cdb-bc3faa7f4422"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'[water swirling, burbling]\\n“IT IS NOT THE STRONGEST OF THE SPECIES THAT SURVIVES, NOR THE MOST INTELLIGENT, IT IS THE ONE THAT IS MOST ADAPTABLE TO CHANGE.”\\nBASED ON THE WORK OF CHARLES DARWIN\\n[calm, mysterious music playing]\\n[music builds]\\n[bubbles burbling]\\n[epic music intensifies]\\nNORTH PACIFIC OCEAN\\nMISSION OCEAN ORIGINS PROJECT “EVOLUTION”\\n[woman 1] I’m here on what’s known as the “seventh continent,” a mass of refuse and garbage over 3 million kilometers in size, four to six times bigger t'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "clean_joker[:500]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "oUoNjSDrbUd7",
        "outputId": "82ee2b44-09e5-4334-e8a9-0ca29accfe29"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'[news anchor on radio] The news never ends.\\nThis is 1080 GCR.\\nYou get all the news you need, all day long.\\nGood morning.\\nIt’s 42 degrees at 10:30 on this Thursday, October 15th.\\nI’m Stan L. Brooks, and here’s what’s happening.\\nIt’s day 18 of the garbage strike, with 10,000 tons of garbage piling up every day.\\nEven the nicest sections of the city are looking like slums.\\nHealth Commissioner Edward O’Rourke is declaring a city-wide state of emergency for the first time in decades.\\n[O’Rourke] There’'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **1.2 Aplicación (3.5 puntos)**\n",
        "\n",
        "Luego de limpiar los guiones, es posible generar la aplicación deseada con el LLM. Esta aplicación tiene que ser capaz de realizar las siguientes tareas.\n",
        "\n",
        "1. Utilizando una plantilla sobre el nombre del archivo o la URL, identifique el supuesto nombre de la película.\n",
        "\n",
        "2. Genere un resumen en español de la película y una nota evaluativa sobre la misma. El resumen debe tener entre 3 a 5 párrafos. Además, obtener una evaluación de la película con una calificación del 1 al 10, utilizando una LLM y el contexto entregado"
      ],
      "metadata": {
        "id": "7Btad-nZ9EyS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **1.2.1 Título de la película (0.5 puntos)** ✅\n",
        "\n",
        "Para obtener el título, utilicé la siguiente plantilla:\n",
        "```\n",
        " template = \"\"\"\n",
        "  What is the movie that appears in the description of this file or url?\n",
        "  You only give me the movie name, nothing more.\n",
        "  document/url: {script_path_url}\n",
        "  \"\"\"\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "QcS80oN2-Gq4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import LLMChain"
      ],
      "metadata": {
        "id": "p5_PXlUag06l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_movie_title(script_path_url):\n",
        "  '''\n",
        "  Escriba su código acá\n",
        "  '''\n",
        "  template = \"\"\"\n",
        "  What is the movie that appears in the description of this file or url?\n",
        "  You only give me the movie name, nothing more.\n",
        "  document/url: {script_path_url}\n",
        "  \"\"\"\n",
        "  prompt_template = PromptTemplate.from_template(template)\n",
        "  prompt_chain = LLMChain(llm=llm, prompt=prompt_template)\n",
        "  result = prompt_chain.invoke({'script_path_url':script_path_url})\n",
        "  return result['text'].strip()"
      ],
      "metadata": {
        "id": "yNIU3mmh-F5W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "script1_title = get_movie_title(dune2_script)\n",
        "script1_title"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Q1n5uIchfNvy",
        "outputId": "ced2d0ef-376e-46b0-ffa6-0e65e87c8fb0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Dune: Part Two'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "script2_title = get_movie_title(underparis_script)\n",
        "script2_title"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "7MKjZ1hWhzKF",
        "outputId": "0b8f1e1d-19b1-4b80-8eae-c4209ed83be1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Under Paris'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "script3_title = get_movie_title(joker_script)\n",
        "script3_title"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "wVCHp5Jmh3qY",
        "outputId": "495ef268-aa8e-4964-9845-930b3ae342f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Joker'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **1.2.2 Resumen (1.0 puntos)** ✅\n",
        "\n",
        "Como se vió en clases, las LLM no pueden manejar cadenas de texto muy largas, esto es debido a que, dependiendo de su naturaleza, solo manejan ventanas de contexto que estan asociadas a caracteristicas de la red y del entrenamiento utilizado.\n",
        "\n",
        "Por ello, es altamente importante que si se desea hacer un resumen del texto, este se haga realizando un tipo de map/reduce sobre el texto. De manera que en cada una de las iteraciones se vaya disminuyendo el tamaño del texto, pero hay que tener cuidado con que le modelo vaya guardando el contexto de escenas previas."
      ],
      "metadata": {
        "id": "muDXLfr0CabX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import MapReduceDocumentsChain, ReduceDocumentsChain\n",
        "from langchain.chains import StuffDocumentsChain, LLMChain\n",
        "from langchain.chains.combine_documents.stuff import StuffDocumentsChain\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter"
      ],
      "metadata": {
        "id": "9sxX87HpDZiV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#No cambiar función\n",
        "\n",
        "def map_reduce_text(script, map_template, reduce_template):\n",
        "\n",
        "  # Map\n",
        "  \"\"\"\n",
        "  map_prompt, crear el prompt desde el template\n",
        "  map_chain, crear la cadena desde el prompt\n",
        "  \"\"\"\n",
        "  map_prompt = PromptTemplate.from_template(map_template)\n",
        "  map_chain = LLMChain(llm=llm, prompt=map_prompt)\n",
        "  # Reduce\n",
        "  \"\"\"\n",
        "  reduce_prompt, crear el prompt desde el template\n",
        "  reduce_chain, crear la cadena desde el prompt\n",
        "  \"\"\"\n",
        "  reduce_prompt = PromptTemplate.from_template(reduce_template)\n",
        "  reduce_chain = LLMChain(llm=llm, prompt=reduce_prompt)\n",
        "  # Combine\n",
        "  \"\"\"\n",
        "  Combinar y reducir los documentos, utilizar StuffDocumentsChain\n",
        "  y ReduceDocuentsChain con un máximo de 4000 tokens\n",
        "  \"\"\"\n",
        "  combine_documents_chain = StuffDocumentsChain(\n",
        "    llm_chain=reduce_chain, document_variable_name=\"script\")\n",
        "\n",
        "  reduce_documents_chain = ReduceDocumentsChain(\n",
        "    combine_documents_chain=combine_documents_chain,\n",
        "    collapse_documents_chain=combine_documents_chain,\n",
        "    token_max=4000,)\n",
        "\n",
        "  # Map/Reduce\n",
        "  \"\"\"\n",
        "  Uilizar MapReduceDocumentsChain\n",
        "  \"\"\"\n",
        "  map_reduce_chain = MapReduceDocumentsChain(\n",
        "    llm_chain=map_chain,\n",
        "    reduce_documents_chain=reduce_documents_chain,\n",
        "    document_variable_name=\"script\",\n",
        "    return_intermediate_steps=False,)\n",
        "\n",
        "\n",
        "  # Text splitter\n",
        "  \"\"\"\n",
        "  Usar RecursiveCharacterTextSplitter\n",
        "  \"\"\"\n",
        "  text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
        "    chunk_size=1000, chunk_overlap=0)\n",
        "\n",
        "  # Resultado\n",
        "  split_script = text_splitter.create_documents([script])\n",
        "  result = map_reduce_chain.invoke(split_script)\n",
        "\n",
        "  return result[\"output_text\"]"
      ],
      "metadata": {
        "id": "jkxFMnCFDcgl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install tiktoken"
      ],
      "metadata": {
        "id": "QEv_uu_jrLy_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# crear templates\n",
        "\n",
        "map_template_summary = \"\"\"The following is a script from a movie\n",
        "{script}\n",
        "Based on this script, please identify the main themes from it.\n",
        "Helpful Answer:\"\"\"\n",
        "\n",
        "reduce_template_summary =\"\"\"The following is a script from a movie:\n",
        "{script}\n",
        "Take it and distill it into a final, consolidated summary of the main themes.\n",
        "Name the movie and then include it's summary.This summary must be in between 3 or 5 paragraphs.\n",
        "It also needs to include a review for this movie rating it from a 1 to a 10, 10 being the highest score.\n",
        "Helpful Answer:\"\"\""
      ],
      "metadata": {
        "id": "HsEJR0IGEZ8V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# imprimir resumenes de películas.\n",
        "answer_summary = map_reduce_text(clean_dune, map_template_summary, reduce_template_summary)\n",
        "print(answer_summary)"
      ],
      "metadata": {
        "id": "ijib42GaIFSI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee2a3306-7f7c-44b3-c2f7-517df684a1f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "## Dune (2021)\n",
            "\n",
            "\"Dune\" is a sprawling epic that plunges viewers into a universe of political intrigue, ecological wonder, and spiritual awakening.  The film follows Paul Atreides, a young noble thrust into the center of a galactic power struggle over the control of a precious resource known as \"spice.\"  Forced to flee his home after a betrayal, Paul finds refuge among the Fremen, a fierce desert people who hold the key to his survival and destiny. \n",
            "\n",
            "As Paul adapts to the harsh environment and embraces the Fremen culture, he begins to understand the power of belief and the weight of his own prophecy. The film masterfully explores themes of power, destiny, and faith. Paul grapples with his prophetic abilities, the weight of his destiny, and the influence of the Bene Gesserit, a powerful organization that has been manipulating events for generations. The Fremen, with their deep reverence for the desert and their unwavering belief in Paul's prophesied role, represent the power of faith and the resilience of a people fighting for their survival.  \n",
            "\n",
            "\"Dune\" is a visually stunning and intellectually stimulating film that captivates the audience with its epic scope and complex characters. The film's masterful blend of science fiction, political drama, and spiritual exploration creates a truly immersive experience. The performances are captivating, particularly Timothée Chalamet as Paul Atreides, whose journey from naive noble to a potential messiah is both compelling and nuanced. The film's breathtaking visuals and haunting score create a truly unforgettable cinematic experience. \n",
            "\n",
            "**Rating:** 9/10 \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "answer_summary2 = map_reduce_text(clean_underparis, map_template_summary, reduce_template_summary)\n",
        "print(answer_summary2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NpNdYVcCshgD",
        "outputId": "ca75d9c3-c0b5-47ac-8ab6-8ce8929747ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain_google_genai.chat_models:Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
            "WARNING:langchain_google_genai.chat_models:Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "## Evolution: A Dive into Environmental Crisis and Human Resilience\n",
            "\n",
            "\"Evolution\" is a captivating film that takes viewers on a journey through a world dramatically altered by human impact on the environment.  The film opens with a stark portrayal of the \"seventh continent,\" a massive plastic island in the Pacific Ocean, setting the stage for a narrative that explores the consequences of pollution and the struggle for survival in a rapidly changing world.  The story centers around a team of scientists dedicated to understanding the ocean's mysteries, but their research is conducted within an environment heavily impacted by human activity.  Through their encounters with sharks, creatures known for their resilience and ability to thrive in challenging environments, the film explores the themes of adaptation and survival in the face of adversity. \n",
            "\n",
            "\"Evolution\" offers a thought-provoking exploration of humanity's relationship with nature, highlighting both the beauty and the fragility of the natural world.  It serves as a stark reminder of the interconnectedness of all life and the consequences of our actions on the planet.  The film leaves viewers pondering the importance of understanding and protecting the environment for future generations, urging us to consider the choices we make and strive for a more sustainable future. \n",
            "\n",
            "**Review:**\n",
            "\n",
            "\"Evolution\" is a visually stunning and emotionally resonant film that delivers a powerful message about the urgency of environmental protection. The film's exploration of complex themes, such as the impact of human pollution, the resilience of life, and the scientific quest to understand the natural world, is both timely and relevant. While the film's pacing might be slow at times, the overall impact is undeniable. \"Evolution\" is a must-see for anyone concerned about the future of our planet and the delicate balance of life on Earth.\n",
            "\n",
            "**Rating:** 9/10 \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Por alguna razón por más que pidamos esta película \"Under Paris\" nos entrega otras películas, asumimos por que se estreno este año, por lo que el modelo no funciona bien para él. Fecha de estreno inicial de Under Paris: 5 de junio de 2024"
      ],
      "metadata": {
        "id": "XS93Us4VwbuJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "answer_summary3 = map_reduce_text(clean_joker, map_template_summary, reduce_template_summary)\n",
        "print(answer_summary3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rX1jMuNXtXcW",
        "outputId": "8e460e70-2cde-4e6a-af23-9e076b3e0cf2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain_google_genai.chat_models:Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "## Joker (2019)\n",
            "\n",
            "\"Joker\" is a chilling and thought-provoking exploration of mental illness, social inequality, and the potential for violence when individuals feel ignored and marginalized.  The film follows Arthur Fleck, a struggling clown with a mental health condition, as he navigates a world that seems determined to crush him. Arthur's descent into madness is fueled by a combination of societal neglect, a lack of support, and a growing sense of alienation. The film powerfully depicts the devastating consequences of mental illness when individuals are denied the resources and compassion they need. \n",
            "\n",
            "Beyond the individual struggles of Arthur, \"Joker\" also paints a bleak picture of a society on the brink of collapse. The film highlights the stark divide between the wealthy elite and the struggling lower class, showcasing the corruption of power and the hypocrisy of those who hold it.  Arthur's resentment towards the \"pricks\" in Gotham City, particularly Thomas Wayne, a symbol of privilege and wealth, reflects a broader critique of the societal structures that perpetuate injustice and inequality.  The film suggests that when individuals are left to suffer in a system that ignores their needs, they may turn to violence as a means of expressing their anger and frustration. \n",
            "\n",
            "\"Joker\" is a powerful and unsettling film that lingers in the mind long after the credits roll. Joaquin Phoenix delivers a tour-de-force performance as Arthur Fleck, capturing the character's descent into madness with chilling accuracy. The film's dark and gritty aesthetic perfectly reflects the bleakness of Arthur's world, creating a sense of unease and dread. While some may find the film's violence disturbing, it serves a purpose, highlighting the consequences of social neglect and the potential for individuals to become radicalized when they feel unheard and unseen.  \"Joker\" is a complex and thought-provoking film that raises important questions about mental health, social inequality, and the responsibility we have to each other. \n",
            "\n",
            "**Rating:** 9/10 \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Adicionalmente, Joaquín sabe que su primo favorito le gusta ``Dune: Part 2`` por lo que le gustaría tener mayor información al respecto, para ello realice las siguientes tareas:\n",
        "\n",
        "\n",
        "3. Genere un gráfico que muestre los personajes de la película con más apariciones en la misma. ✅\n",
        "4. Genere una tabla en pandas con los 3 personajes que más aparecen, indicando el nombre del actor y su edad actual más uno (ojo edad + 1).\n",
        "5. Cree una función que responda preguntas sobre la película basándose en la información del texto entregado (OJO: las preguntas y salidas deben ser en español). Luego, responda las siguientes preguntas:\n",
        "* ¿Qué y quién es Lisan al-Gaib?\n",
        "* ¿Qué personaje no cree en la profecía pero es parte de ella?\n",
        "* ¿Cuál es el objetivo de Feyd-Rautha?\n",
        "6. Utilizando el top 3 de personajes que más aparecen en la película, genere con el modelo LLM y utilizando el contexto del guion, las 6 estadísticas que demuestren las habilidades de los personajes: Intelligence, Strength, Charisma, Wisdom, Emotional Resilience, y Creativity."
      ],
      "metadata": {
        "id": "dD7YHYZSIWbJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **1.2.3 Personajes (0.5 puntos)**\n",
        "\n",
        "En la siguiente sección, tiene que entregar un template de personajes y redicción"
      ],
      "metadata": {
        "id": "e_vdMMceJZBu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "map_template_characters = \"\"\"The following is a movie script:\n",
        "{script}\n",
        "Identify all characters mentioned in the script.\n",
        "Characters appear in the format \"[name_character]\" within the text.\n",
        "Ignore every other name that does not follow this format.\n",
        "Do not add any additional information to get the names, like sources\n",
        "from books or comics of the same name.\n",
        "Helpful Answer:\n",
        "\"\"\"\n",
        "\n",
        "reduce_template_characters = \"\"\"Here are summaries from the script:\n",
        "{script}\n",
        "From these summaries, provide a final list in Python list format stored in a variable named 'characters_name'.\n",
        "The list must only contain names. The list must not contain text characters like '\\n' and of the sort.\n",
        "Helpful Answer:\n",
        "\"\"\"\n",
        "\n",
        "answer_character_list = map_reduce_text(\n",
        "    clean_dune,\n",
        "    map_template_characters,\n",
        "    reduce_template_characters\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fHJMFqQzFArn",
        "outputId": "564537d6-a1d2-45e4-a758-a367cf244a14"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain_google_genai.chat_models:Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
            "WARNING:langchain_google_genai.chat_models:Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
            "WARNING:langchain_google_genai.chat_models:Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
            "WARNING:langchain_google_genai.chat_models:Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
            "WARNING:langchain_google_genai.chat_models:Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 16.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
            "WARNING:langchain_google_genai.chat_models:Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 32.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "answer_character_list"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "id": "q9ierRM-ClPw",
        "outputId": "7149dffb-b00a-4275-f751-72579a186e37"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"```python\\ncharacters_name = ['Irulan', 'Paul', 'Jessica', 'Stilgar', 'Chani', 'Harkonnen soldier', 'Harkonnen commander', 'Rabban', 'Fremen sentinel', 'sentinel leader', 'Jamis', 'Shishakli', 'old watermaster', 'Fedaykin fighter', 'Usul', 'Muad’Dib', 'Baron Harkonnen', 'male Fedaykin fighter', 'nun', 'Emperor', 'Reverend Mother Mohiam', 'Feyd-Rautha Harkonnen', 'Feyd-Rautha', 'weapon master', 'attendant', 'slave master', 'Lanville', 'Lady Margot Fenring', 'Bene Gesserit sister 1', 'Bene Gesserit sister 2', 'gladiator arena announcer', 'Baron Harkonnen', 'Rabban', 'Gurney', 'Maker Keeper', 'Alia', 'Rabban Harkonnen', 'Paul Muad’Dib Atreides', 'Bashar']\\n```\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 251
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import plotly.express as px\n",
        "from itertools import count\n",
        "import ast\n",
        "import re\n",
        "import numpy as np\n",
        "\n",
        "def plot_characters(answer_character_list):\n",
        "  # Clear answer\n",
        "  characters_list = re.findall(r\"'(.*?)'\", answer_character_list)\n",
        "\n",
        "  # distil the characters output\n",
        "  \"\"\"\n",
        "  Recomendación, utilizar un diccionario para ordenar los personajes\n",
        "  \"\"\"\n",
        "  count_characters = {}\n",
        "  for character in characters_list:\n",
        "    pattern = rf'\\[{re.escape(character)}\\]'\n",
        "    matches = re.findall(pattern, clean_dune)\n",
        "    count_characters[character] = len(matches)\n",
        "\n",
        "  # Create dataframe\n",
        "  \"\"\"\n",
        "  De diccionario a DataFrame\n",
        "  \"\"\"\n",
        "  df_characters = pd.DataFrame(list(count_characters.items()), columns=['Personaje', 'Frecuencia en el script'])\n",
        "  df_characters = df_characters.sort_values(by='Frecuencia en el script', ascending=False)\n",
        "\n",
        "  # Graficar datos\n",
        "\n",
        "  fig = px.bar(\n",
        "      df_characters,\n",
        "      x='Personaje',\n",
        "      y='Frecuencia en el script',\n",
        "      title='Personajes de la película y su frecuencia',\n",
        "      template='plotly_white'\n",
        "  )\n",
        "  fig.show()\n",
        "\n",
        "  #Retornar los personajes\n",
        "  return df_characters[['Personaje']].reset_index(drop=True)"
      ],
      "metadata": {
        "id": "hJQ-RPYJKOKU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = plot_characters(answer_character_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "8QKbjLVI0y9t",
        "outputId": "9ae349e4-7247-4285-85ee-e3c61eba599a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.24.1.min.js\"></script>                <div id=\"da597d62-0118-454d-9d29-93bfbf71238f\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"da597d62-0118-454d-9d29-93bfbf71238f\")) {                    Plotly.newPlot(                        \"da597d62-0118-454d-9d29-93bfbf71238f\",                        [{\"alignmentgroup\":\"True\",\"hovertemplate\":\"Personaje=%{x}\\u003cbr\\u003eFrecuencia en el script=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"\",\"marker\":{\"color\":\"#636efa\",\"pattern\":{\"shape\":\"\"}},\"name\":\"\",\"offsetgroup\":\"\",\"orientation\":\"v\",\"showlegend\":false,\"textposition\":\"auto\",\"x\":[\"Paul\",\"Chani\",\"Stilgar\",\"Jessica\",\"Feyd-Rautha\",\"Gurney\",\"Rabban\",\"Lady Margot Fenring\",\"Baron Harkonnen\",\"Harkonnen commander\",\"Shishakli\",\"Irulan\",\"Emperor\",\"Harkonnen soldier\",\"Reverend Mother Mohiam\",\"Alia\",\"Bashar\",\"Fedaykin fighter\",\"slave master\",\"Bene Gesserit sister 1\",\"Jamis\",\"Bene Gesserit sister 2\",\"Lanville\",\"Usul\",\"nun\",\"sentinel leader\",\"Fremen sentinel\",\"old watermaster\",\"Muad’Dib\",\"male Fedaykin fighter\",\"weapon master\",\"attendant\",\"Feyd-Rautha Harkonnen\",\"Maker Keeper\",\"gladiator arena announcer\",\"Rabban Harkonnen\",\"Paul Muad’Dib Atreides\"],\"xaxis\":\"x\",\"y\":[73,42,35,32,15,14,9,7,6,5,5,4,4,4,3,2,2,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0],\"yaxis\":\"y\",\"type\":\"bar\"}],                        {\"template\":{\"data\":{\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"white\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"#C8D4E3\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"white\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"radialaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"yaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"zaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"caxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Personaje\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Frecuencia en el script\"}},\"legend\":{\"tracegroupgap\":0},\"title\":{\"text\":\"Personajes de la película y su frecuencia\"},\"barmode\":\"relative\"},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('da597d62-0118-454d-9d29-93bfbf71238f');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **1.2.4 Actores principales (0.75 puntos)**\n",
        "\n",
        "Importante saber que el script **no** maneja información de los actores, por ello, es importante que nuestra LLM tenga acceso a internet, de manera de poder realizar búsquedas que nos ayuden a completar la información consultada.\n",
        "\n",
        "Para esto, utilizaremos agentes combinados con react para realzar la consulta y asegurarnos de que la respuesta es correcta."
      ],
      "metadata": {
        "id": "2G2dx0XoLis4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.agents import load_tools\n",
        "from langchain.agents import AgentType, initialize_agent"
      ],
      "metadata": {
        "id": "A9CHzsLDKPeL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Key para realizar una busqueda\n",
        "os.environ[\"SERPER_API_KEY\"] = 'd63e62662ef63eb9e44ab133d191f7a99a0024a3'"
      ],
      "metadata": {
        "id": "4ZSclMoFMGSO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "personajes = df.Personaje.to_list()"
      ],
      "metadata": {
        "id": "r6U6E49hThHS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_actors_and_age(character):\n",
        "\n",
        "  # Inicializar tools y agente.\n",
        "  tools = load_tools([\"google-serper\", \"llm-math\"], llm=llm)\n",
        "  agent = initialize_agent(tools, llm, agent=\"zero-shot-react-description\", verbose=True)\n",
        "\n",
        "  # Crear template de query\n",
        "  query_template = \"\"\"  Here is a list of characters from the movie {movie}: {characters}\n",
        "    For each character, find the name of the actor who played them and their current age plus one year (age + 1).\n",
        "    Provide the results in the following format:\n",
        "    Character: [character name], Actor: [actor name], Age+1: [actor age + 1].\n",
        "  \"\"\"\n",
        "  # Crear prompt y usar agente para la búsqueda.\n",
        "  reduce_prompt = PromptTemplate.from_template(query_template)\n",
        "\n",
        "  # Retornar Nombre y Edad + 1\n",
        "  reduce_prompt = PromptTemplate.from_template(query_template)\n",
        "  agent_templated = reduce_prompt | agent\n",
        "  agent_answer = agent_templated.invoke(\n",
        "      {\n",
        "          'movie': script1_title,\n",
        "          'characters': personajes\n",
        "      }\n",
        "  )\n",
        "  return agent_answer['output']"
      ],
      "metadata": {
        "id": "sbGuaD6PMMA5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_actors_and_age(personajes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 654
        },
        "id": "TF00YUnpPx09",
        "outputId": "29b4c6cd-348b-4351-9173-6ee482519be3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mThought: I need to find the actors and their ages for each character in the list. I can use Google Search to find this information.\n",
            "Action: google_serper\n",
            "Action Input: \"Dune Part Two cast and age\"\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3mScience fiction epic that serves as a continuation of 2021's Dune. Paul Atreides reunites with the Fremen as he seeks revenge against those who destroyed his ... Timothée Chalamet · Paul Atreides ; Zendaya · Chani ; Rebecca Ferguson · Jessica ; Javier Bardem · Stilgar ; Josh Brolin · Gurney Halleck. Your guide to the full cast and characters of Dune: Part Two which is led by Timothée Chalamet as Paul Atreides and Zendaya as Chani ... Dune: Part Two (2024) cast and crew credits, including actors, actresses, directors, writers and more. Missing: age | Show results with:age. Share on Social Media · Timothée Chalamet as Paul Atreides · Zendaya as Chani · Javier Bardem as Stilgar · Rebecca Ferguson as Lady Jessica · Josh ... The Dune 2 cast features both returning actors from the first film, like Timothée Chalamet and Zendaya, and newcomers like Florence Pugh. Timothée Chalamet, Rebecca Ferguson, Josh Brolin, Stellan Skarsgård, Dave Bautista, Zendaya, Charlotte Rampling, and Javier Bardem reprise their roles from the ... ... Age,Dune 2 Real Name,Dune 2 Real Life Actors,Dune 2024,Are,Real Name,Actors 2024 ... Duration: 2:58. Posted: Mar 11, 2024. 'Dune: Part Two' Cast and Character Guide: Who Plays Who? ; Zendaya as Chani. Timothée Chalamet, Rebecca Ferguson, Josh Brolin, Stellan Skarsgård, Dave Bautista, Stephen McKinley Henderson, Zendaya, Charlotte Rampling, and ...\u001b[0m\n",
            "Thought:"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-322-6f4b890d6f23>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_actors_and_age\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpersonajes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-321-1cc00107339a>\u001b[0m in \u001b[0;36mget_actors_and_age\u001b[0;34m(character)\u001b[0m\n\u001b[1;32m     17\u001b[0m   \u001b[0mreduce_prompt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPromptTemplate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_template\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery_template\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m   \u001b[0magent_templated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreduce_prompt\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m   agent_answer = agent_templated.invoke(\n\u001b[0m\u001b[1;32m     20\u001b[0m       {\n\u001b[1;32m     21\u001b[0m           \u001b[0;34m'movie'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mscript1_title\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/runnables/base.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   2505\u001b[0m                     \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2506\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2507\u001b[0;31m                     \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2508\u001b[0m         \u001b[0;31m# finish the root run\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2509\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    164\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m             \u001b[0mrun_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_chain_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m         \u001b[0mrun_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_chain_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    154\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m             outputs = (\n\u001b[0;32m--> 156\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mnew_arg_supported\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m                 \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/agents/agent.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs, run_manager)\u001b[0m\n\u001b[1;32m   1431\u001b[0m         \u001b[0;31m# We now enter the agent loop (until it returns something).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1432\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_continue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime_elapsed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1433\u001b[0;31m             next_step_output = self._take_next_step(\n\u001b[0m\u001b[1;32m   1434\u001b[0m                 \u001b[0mname_to_tool_map\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1435\u001b[0m                 \u001b[0mcolor_mapping\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/agents/agent.py\u001b[0m in \u001b[0;36m_take_next_step\u001b[0;34m(self, name_to_tool_map, color_mapping, inputs, intermediate_steps, run_manager)\u001b[0m\n\u001b[1;32m   1137\u001b[0m     ) -> Union[AgentFinish, List[Tuple[AgentAction, str]]]:\n\u001b[1;32m   1138\u001b[0m         return self._consume_next_step(\n\u001b[0;32m-> 1139\u001b[0;31m             [\n\u001b[0m\u001b[1;32m   1140\u001b[0m                 \u001b[0ma\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1141\u001b[0m                 for a in self._iter_next_step(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/agents/agent.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1137\u001b[0m     ) -> Union[AgentFinish, List[Tuple[AgentAction, str]]]:\n\u001b[1;32m   1138\u001b[0m         return self._consume_next_step(\n\u001b[0;32m-> 1139\u001b[0;31m             [\n\u001b[0m\u001b[1;32m   1140\u001b[0m                 \u001b[0ma\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1141\u001b[0m                 for a in self._iter_next_step(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/agents/agent.py\u001b[0m in \u001b[0;36m_iter_next_step\u001b[0;34m(self, name_to_tool_map, color_mapping, inputs, intermediate_steps, run_manager)\u001b[0m\n\u001b[1;32m   1165\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1166\u001b[0m             \u001b[0;31m# Call the LLM to see what to do.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1167\u001b[0;31m             output = self.agent.plan(\n\u001b[0m\u001b[1;32m   1168\u001b[0m                 \u001b[0mintermediate_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1169\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_child\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mrun_manager\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/agents/agent.py\u001b[0m in \u001b[0;36mplan\u001b[0;34m(self, intermediate_steps, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    729\u001b[0m         \"\"\"\n\u001b[1;32m    730\u001b[0m         \u001b[0mfull_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_full_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mintermediate_steps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 731\u001b[0;31m         \u001b[0mfull_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mllm_chain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfull_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    732\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_parser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfull_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    733\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    315\u001b[0m                 \u001b[0mcompletion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mllm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madjective\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"funny\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m         \"\"\"\n\u001b[0;32m--> 317\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_key\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    318\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m     \u001b[0;32masync\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mapredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mCallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py\u001b[0m in \u001b[0;36mwarning_emitting_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    166\u001b[0m                 \u001b[0mwarned\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m                 \u001b[0memit_warning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 168\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    169\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m         \u001b[0;32masync\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mawarning_emitting_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, run_name, include_run_info)\u001b[0m\n\u001b[1;32m    381\u001b[0m         }\n\u001b[1;32m    382\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 383\u001b[0;31m         return self.invoke(\n\u001b[0m\u001b[1;32m    384\u001b[0m             \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m             \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRunnableConfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    164\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m             \u001b[0mrun_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_chain_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m         \u001b[0mrun_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_chain_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    154\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m             outputs = (\n\u001b[0;32m--> 156\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mnew_arg_supported\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m                 \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs, run_manager)\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0mrun_manager\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mCallbackManagerForChainRun\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m     ) -> Dict[str, str]:\n\u001b[0;32m--> 127\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, input_list, run_manager)\u001b[0m\n\u001b[1;32m    137\u001b[0m         \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_child\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mrun_manager\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mllm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBaseLanguageModel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m             return self.llm.generate_prompt(\n\u001b[0m\u001b[1;32m    140\u001b[0m                 \u001b[0mprompts\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m                 \u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\u001b[0m in \u001b[0;36mgenerate_prompt\u001b[0;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    675\u001b[0m     ) -> LLMResult:\n\u001b[1;32m    676\u001b[0m         \u001b[0mprompt_messages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_messages\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprompts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 677\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt_messages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    678\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    679\u001b[0m     async def agenerate_prompt(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[1;32m    532\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mrun_managers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m                     \u001b[0mrun_managers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_llm_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mLLMResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 534\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    535\u001b[0m         flattened_outputs = [\n\u001b[1;32m    536\u001b[0m             \u001b[0mLLMResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerations\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mllm_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mllm_output\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[list-item]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[1;32m    522\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m                 results.append(\n\u001b[0;32m--> 524\u001b[0;31m                     self._generate_with_cache(\n\u001b[0m\u001b[1;32m    525\u001b[0m                         \u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    526\u001b[0m                         \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\u001b[0m in \u001b[0;36m_generate_with_cache\u001b[0;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    747\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    748\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_generate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"run_manager\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 749\u001b[0;31m                 result = self._generate(\n\u001b[0m\u001b[1;32m    750\u001b[0m                     \u001b[0mmessages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_manager\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    751\u001b[0m                 )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_google_genai/chat_models.py\u001b[0m in \u001b[0;36m_generate\u001b[0;34m(self, messages, stop, run_manager, tools, functions, safety_settings, tool_config, generation_config, **kwargs)\u001b[0m\n\u001b[1;32m    765\u001b[0m             \u001b[0mgeneration_config\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgeneration_config\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m         )\n\u001b[0;32m--> 767\u001b[0;31m         response: GenerateContentResponse = _chat_with_retry(\n\u001b[0m\u001b[1;32m    768\u001b[0m             \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    769\u001b[0m             \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_google_genai/chat_models.py\u001b[0m in \u001b[0;36m_chat_with_retry\u001b[0;34m(generation_method, **kwargs)\u001b[0m\n\u001b[1;32m    194\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_chat_with_retry\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tenacity/__init__.py\u001b[0m in \u001b[0;36mwrapped_f\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    330\u001b[0m         )\n\u001b[1;32m    331\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mwrapped_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mretry_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mWrappedFn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tenacity/__init__.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    467\u001b[0m         \u001b[0mretry_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRetryCallState\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretry_object\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    468\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 469\u001b[0;31m             \u001b[0mdo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretry_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretry_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    470\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDoAttempt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    471\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tenacity/__init__.py\u001b[0m in \u001b[0;36miter\u001b[0;34m(self, retry_state)\u001b[0m\n\u001b[1;32m    368\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0maction\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactions\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 370\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretry_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    371\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    372\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tenacity/__init__.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(rs)\u001b[0m\n\u001b[1;32m    390\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_post_retry_check_actions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretry_state\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"RetryCallState\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_explicit_retry\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretry_run_result\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 392\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_add_action_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mrs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mrs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutcome\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    393\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    449\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mCancelledError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mFINISHED\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 451\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/concurrent/futures/_base.py\u001b[0m in \u001b[0;36m__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    401\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 403\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    404\u001b[0m             \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    405\u001b[0m                 \u001b[0;31m# Break a reference cycle with the exception in self._exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tenacity/__init__.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    470\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDoAttempt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    471\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 472\u001b[0;31m                     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    473\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# noqa: B902\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m                     \u001b[0mretry_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[arg-type]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_google_genai/chat_models.py\u001b[0m in \u001b[0;36m_chat_with_retry\u001b[0;34m(**kwargs)\u001b[0m\n\u001b[1;32m    176\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_chat_with_retry\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mgeneration_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m         \u001b[0;31m# Do not retry for these errors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFailedPrecondition\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\u001b[0m in \u001b[0;36mgenerate_content\u001b[0;34m(self, request, model, contents, retry, timeout, metadata)\u001b[0m\n\u001b[1;32m    825\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    826\u001b[0m         \u001b[0;31m# Send the request.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 827\u001b[0;31m         response = rpc(\n\u001b[0m\u001b[1;32m    828\u001b[0m             \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    829\u001b[0m             \u001b[0mretry\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretry\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, timeout, retry, *args, **kwargs)\u001b[0m\n\u001b[1;32m    111\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"metadata\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/api_core/retry.py\u001b[0m in \u001b[0;36mretry_wrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    347\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maximum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmultiplier\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_multiplier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m             )\n\u001b[0;32m--> 349\u001b[0;31m             return retry_target(\n\u001b[0m\u001b[1;32m    350\u001b[0m                 \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_predicate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/api_core/retry.py\u001b[0m in \u001b[0;36mretry_target\u001b[0;34m(target, predicate, sleep_generator, timeout, on_error, **kwargs)\u001b[0m\n\u001b[1;32m    189\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0msleep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msleep_generator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 191\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m         \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\u001b[0m in \u001b[0;36mfunc_with_timeout\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    118\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"timeout\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtime_since_first_attempt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc_with_timeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\u001b[0m in \u001b[0;36merror_remapped_callable\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0merror_remapped_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcallable_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mgrpc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRpcError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_grpc_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/grpc/_channel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[0m\n\u001b[1;32m   1176\u001b[0m             \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1177\u001b[0m             \u001b[0mcall\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1178\u001b[0;31m         \u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_blocking\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1179\u001b[0m             \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcredentials\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwait_for_ready\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompression\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/grpc/_channel.py\u001b[0m in \u001b[0;36m_blocking\u001b[0;34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[0m\n\u001b[1;32m   1160\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_registered_call_handle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1161\u001b[0m             )\n\u001b[0;32m-> 1162\u001b[0;31m             \u001b[0mevent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1163\u001b[0m             \u001b[0m_handle_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_response_deserializer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1164\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32msrc/python/grpcio/grpc/_cython/_cygrpc/channel.pyx.pxi\u001b[0m in \u001b[0;36mgrpc._cython.cygrpc.SegregatedCall.next_event\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32msrc/python/grpcio/grpc/_cython/_cygrpc/channel.pyx.pxi\u001b[0m in \u001b[0;36mgrpc._cython.cygrpc._next_call_event\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32msrc/python/grpcio/grpc/_cython/_cygrpc/channel.pyx.pxi\u001b[0m in \u001b[0;36mgrpc._cython.cygrpc._next_call_event\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32msrc/python/grpcio/grpc/_cython/_cygrpc/completion_queue.pyx.pxi\u001b[0m in \u001b[0;36mgrpc._cython.cygrpc._latent_event\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32msrc/python/grpcio/grpc/_cython/_cygrpc/completion_queue.pyx.pxi\u001b[0m in \u001b[0;36mgrpc._cython.cygrpc._internal_latent_event\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32msrc/python/grpcio/grpc/_cython/_cygrpc/completion_queue.pyx.pxi\u001b[0m in \u001b[0;36mgrpc._cython.cygrpc._next\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Explicar metodología utilizada**\n",
        "\n",
        ":"
      ],
      "metadata": {
        "id": "Kpf9H61qMxal"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **1.2.5 Personajes Stats (0.5 puntos)**\n",
        "\n",
        "Esta parte es similar al punto 2. La clave esta en crear un buen prompting que nos permita generar las estadísticas basandonos en una búsqueda por map/reduce.\n",
        "\n",
        "Tras la búsqueda, la idea es tener una función de Python que nos permita generar el gráfico deseado y tener el resumen de los personajes.\n"
      ],
      "metadata": {
        "id": "MtQqA40sM09E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "def map_reduce_text(script, character):\n",
        "  # Map\n",
        "  map_template = \"\"\"\n",
        "  Crear template, utilizar las palabras claves:\n",
        "  Intelligence, Charisma, Strength, Wisdom, Emotional Resilience and Creativity.\n",
        "  \"\"\"\n",
        "\n",
        "  # crear prompt y cadena\n",
        "  map_template += template_complemt\n",
        "  map_prompt = # ...\n",
        "  map_chain = # ...\n",
        "\n",
        "  # Reduce\n",
        "  reduce_template = \"\"\"\n",
        "  Crear prompt de reducción.\n",
        "  Reducir, dado el perfil, en escala del 1 al 10 las cualidades mencionadas\n",
        "  \"\"\"\n",
        "  reduce_prompt = # ...\n",
        "  reduce_chain = # ...\n",
        "\n",
        "  # Reduce\n",
        "  \"\"\"\n",
        "  Reducir y combinar los documentos con un máximo de 4000 tokens\n",
        "  \"\"\"\n",
        "\n",
        "  # Map/Reduce\n",
        "  \"\"\"\n",
        "  Uilizar MapReduceDocumentsChain\n",
        "  \"\"\"\n",
        "\n",
        "\n",
        "  # Text splitter\n",
        "  \"\"\"\n",
        "  Usar RecursiveCharacterTextSplitter\n",
        "  \"\"\"\n",
        "\n",
        "  result = map_reduce_chain.invoke(split_script)\n",
        "  return result[\"output_text\"]\n",
        "\n",
        "\n",
        "# Formato del perfil\n",
        "def format_profile(answer_character_profile):\n",
        "  \"\"\"\n",
        "  Crear un json con las caracteristicas y que retorne\n",
        "  (final_profile, stats) del personaje\n",
        "  \"\"\"\n",
        "  return (final_profile, stats)\n"
      ],
      "metadata": {
        "id": "ha1zVrtkNaF-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Escriba su respuesta acá"
      ],
      "metadata": {
        "id": "T_wwMRm7PbXC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_profile, stats = format_profile(answer_character_profile)"
      ],
      "metadata": {
        "id": "0oduYAOZPaL_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(final_profile)"
      ],
      "metadata": {
        "id": "eOQ8yMG5PhGT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Función para gráficar stats. No Tocar.\n",
        "\n",
        "import plotly.graph_objects as go\n",
        "import numpy as np\n",
        "\n",
        "def plot_stats(stats, character_name=\"Paul Atreides\"):\n",
        "    base_stats = [\n",
        "        \"Intelligence\", \"Charisma\", \"Strength\",\n",
        "        \"Wisdom\", \"Emotional Resilience\", \"Creativity\"\n",
        "    ]\n",
        "    for stat in base_stats:\n",
        "        if stat not in stats:\n",
        "            stats[stat] = 0\n",
        "\n",
        "    labels = list(stats.keys())\n",
        "    stats_values = list(stats.values())\n",
        "    stats_values += stats_values[:1]\n",
        "    labels += labels[:1]\n",
        "\n",
        "    # Plotly figure\n",
        "    fig = go.Figure()\n",
        "    fig.add_trace(go.Scatterpolar(\n",
        "        r=stats_values,\n",
        "        theta=labels,\n",
        "        fill='toself',\n",
        "        name=character_name\n",
        "    ))\n",
        "\n",
        "    fig.update_layout(\n",
        "        polar=dict(\n",
        "            radialaxis=dict(\n",
        "                visible=True,\n",
        "                range=[0, max(stats_values)]\n",
        "            )\n",
        "        ),\n",
        "        showlegend=False,\n",
        "        title=character_name\n",
        "    )\n",
        "\n",
        "    return fig\n",
        "\n",
        "fig = plot_stats(stats)"
      ],
      "metadata": {
        "id": "IXAHPyRSP6HY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Comentar (0.25 puntos)**\n",
        "Explicar metodología y secuencia lógica de cada una de las respuestas. Además responda:\n",
        "\n",
        "* ¿Qué otras tareas se podría realizar? De dos ejemplos con la metodología asociada.\n",
        "\n",
        "* ¿Cual es la importancia de los prompt y como estos afectan al desempeño de los LLM?\n",
        "\n",
        "* ¿Alguna de sus respuestas fue una 'alucinación'? ¿Por qué sucede esto?"
      ],
      "metadata": {
        "id": "_APhHBPXQXTX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **2. Reinforcement Learning (2.0 puntos)**\n",
        "\n",
        "En esta sección van a usar métodos de RL para resolver dos problemas interesantes: `Blackjack` y `LunarLander`."
      ],
      "metadata": {
        "id": "0hmHHQ9BuyAG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -qqq gymnasium stable_baselines3\n",
        "!pip install -qqq swig\n",
        "!pip install -qqq gymnasium[box2d]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gOcejYb6uzOO",
        "outputId": "72dfe85d-6629-4c3f-d6a0-0d1952da5c16"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m953.9/953.9 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m182.3/182.3 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m72.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m21.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m374.4/374.4 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for box2d-py (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **2.1 Blackjack (1.0 puntos)**\n",
        "\n",
        "<p align=\"center\">\n",
        "  <img src=\"https://www.recreoviral.com/wp-content/uploads/2016/08/s3.amazonaws.com-Math.gif\"\n",
        "\" width=\"400\">\n",
        "</p>\n",
        "\n",
        "Joaquín es fanático del Blackjack, por lo que en esta subsección implementarán métodos de RL y así generar una estrategia para que pueda ~~ir al casino a  hacerse millonario~~ aprender a resolver problemas mediante RL.\n",
        "\n",
        "Comencemos primero preparando el ambiente. El siguiente bloque de código transforma las observaciones del ambiente a `np.array`:\n"
      ],
      "metadata": {
        "id": "qBPet_Mq8dX9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gymnasium as gym\n",
        "from gymnasium.spaces import MultiDiscrete\n",
        "import numpy as np\n",
        "\n",
        "class FlattenObservation(gym.ObservationWrapper):\n",
        "    def __init__(self, env):\n",
        "        super(FlattenObservation, self).__init__(env)\n",
        "        self.observation_space = MultiDiscrete(np.array([32, 11, 2]))\n",
        "\n",
        "    def observation(self, observation):\n",
        "        return np.array(observation).flatten()\n",
        "\n",
        "# Create and wrap the environment\n",
        "env = gym.make(\"Blackjack-v1\")\n",
        "env = FlattenObservation(env)"
      ],
      "metadata": {
        "id": "LpZ8bBKk9ZlU"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **2.1.1 Descripción de MDP (0.2 puntos)**\n",
        "\n",
        "Entregue una breve descripción sobre el ambiente [Blackjack](https://gymnasium.farama.org/environments/toy_text/blackjack/) y su formulación en MDP, distinguiendo de forma clara y concisa los estados, acciones y recompensas."
      ],
      "metadata": {
        "id": "ZJ6J1_-Y9nHO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Estados**\n",
        "1. Suma actual del jugador (entero)\n",
        "2. Valor de la carta visible del crupier (1-10, donde 1 representa un as)\n",
        "3. Si el jugador tiene un as usable (0 o 1)\n",
        "\n",
        "**Acciones:** El espacio de acciones es discreto con dos posibilidades\n",
        "- 0: Plantarse (dejar de recibir cartas)\n",
        "- 1: Pedir (solicitar una carta adicional)\n",
        "\n",
        "**Recompensas:** La función de recompensa se define como\n",
        "- Ganar: +1\n",
        "- Perder: -1\n",
        "- Empate: 0\n",
        "- Ganar con un blackjack natural:\n",
        "  - +1.5 si natural=True\n",
        "  - +1 si natural=False"
      ],
      "metadata": {
        "id": "N0nNGxfAW_SZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **2.1.2 Generando un Baseline (0.2 puntos)**\n",
        "\n",
        "* Simule un escenario en donde se escojan acciones aleatorias. Repita esta\n",
        "simulación 5000 veces y reporte el promedio y desviación de las recompensas.\n",
        "* ¿Cómo calificaría el performance de esta política?\n",
        "* ¿Cómo podría interpretar las recompensas obtenidas?"
      ],
      "metadata": {
        "id": "pmcX6bRC9agQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "episodes = 5000\n",
        "rewards = np.zeros(episodes)\n",
        "\n",
        "for episode in range(episodes):\n",
        "    obs, info = env.reset()\n",
        "    done = False\n",
        "\n",
        "    while not done:\n",
        "        action = env.action_space.sample()\n",
        "        obs, reward, done, _, info = env.step(action)\n",
        "\n",
        "    rewards[episode] = reward\n",
        "\n",
        "mean_reward = np.mean(rewards)\n",
        "std_reward = np.std(rewards)\n",
        "\n",
        "print(\"Mean reward:\", mean_reward)\n",
        "print(\"Standard deviation of rewards:\", std_reward)"
      ],
      "metadata": {
        "id": "RHCfKN7NGi1K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca0282d1-0a32-4807-f29d-92f7b7aca1a0"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean reward: -0.416\n",
            "Standard deviation of rewards: 0.8859706541415465\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**¿Cómo calificaría el performance de esta política?**\n",
        "\n",
        "La política de seleccionar acciones aleatorias en el Blackjack es **deficiente**. La recompensa promedio es negativa (-0.416), indicando pérdidas en promedio. La alta desviación estándar (0.886) muestra una gran variabilidad en las recompensas, esperable por las decisiones aleatorias.\n",
        "\n",
        "**¿Cómo podría interpretar las recompensas obtenidas?**\n",
        "\n",
        "- **Recompensa promedio negativa** (-0.416): Esto significa que en promedio, el jugador termina perdiendo dinero, si uno sigue esta estrategia a largo plazo, es más probable que termine con menos dinero del que empezó.\n",
        "- **Alta desviación estándar** (0.886): Esto muestra que las recompensas pueden variar mucho de una ronda a otra, a veces se puede ganar un poco más, pero también se puede perder bastante.\n"
      ],
      "metadata": {
        "id": "DSpJ8RUGXK_N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **2.1.3 Entrenamiento de modelo (0.2 puntos)**\n",
        "\n",
        "A partir del siguiente [enlace](https://stable-baselines3.readthedocs.io/en/master/guide/algos.html), escoja un modelo de `stable_baselines3` y entrenelo para resolver el ambiente `Blackjack`."
      ],
      "metadata": {
        "id": "LEO_dY4x_SJu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from stable_baselines3 import DQN\n",
        "from stable_baselines3.common.evaluation import evaluate_policy\n",
        "\n",
        "# Instantiate the agent\n",
        "model = DQN(\"MlpPolicy\", env, verbose=0)\n",
        "\n",
        "# Train the agent and display a progress bar\n",
        "model.learn(total_timesteps=int(2e5), progress_bar=True)"
      ],
      "metadata": {
        "id": "T0sp8XWsGg4P",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51,
          "referenced_widgets": [
            "b248ca1993694afd90401e60c7f4b53b",
            "8302ee2ded67482090417663d456adcf"
          ]
        },
        "outputId": "5b8ce387-28b3-4205-d50f-003edcb7308a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Output()"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b248ca1993694afd90401e60c7f4b53b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<stable_baselines3.dqn.dqn.DQN at 0x7850510132b0>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **2.1.4 Evaluación de modelo (0.2 puntos)**\n",
        "\n",
        "* Repita el ejercicio 2.1.2 pero utilizando el modelo entrenado.\n",
        "* ¿Cómo es el performance de su agente?\n",
        "* ¿Es mejor o peor que el escenario baseline?"
      ],
      "metadata": {
        "id": "E-bpdb8wZID1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from stable_baselines3.common.evaluation import evaluate_policy\n",
        "\n",
        "mean_reward, std_reward = evaluate_policy(model, env, n_eval_episodes = 5_000)\n",
        "mean_reward, std_reward"
      ],
      "metadata": {
        "id": "S7jdmnTwGePD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3fda23f0-6630-4502-f7c5-d45ab79f356e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/stable_baselines3/common/evaluation.py:67: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(-0.0482, 0.9498824979964626)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para evaluar el desempeño del agente entrenado con el modelo de DQN en el problema de Blackjack, consideramos:\n",
        "\n",
        "- Promedio de recompensas: -0.0482\n",
        "- Desviación estándar de las recompensas: 0.9499\n",
        "\n",
        "**Desempeño del Agente**\n",
        "\n",
        "El agente entrenado muestra una recompensa promedio cercana a cero (-0.0482), indicando resultados neutros en promedio. Sin embargo, la alta desviación estándar (0.9498) revela que las recompensas varían mucho entre simulaciones, debido a la naturaleza aleatoria del juego y las decisiones tomadas por el agente.\n",
        "\n",
        "**Comparación con el Baseline**\n",
        "\n",
        "El agente entrenado muestra un desempeño ligeramente mejor, con un promedio de recompensas más cercano a cero, lo que sugiere una estrategia más informada que podría estar minimizando las pérdidas promedio. Sin embargo, la alta variabilidad en las recompensas indica que aún hay espacio para mejorar la consistencia y la efectividad del agente en el juego de Blackjack.\n"
      ],
      "metadata": {
        "id": "abPF6hrpXdGB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **2.1.5 Estudio de acciones (0.2 puntos)**\n",
        "\n",
        "* Genere una función que reciba un estado y retorne la accion del agente.\n",
        "* Luego, use esta función para entregar la acción escogida frente a los siguientes escenarios:\n",
        "\n",
        "  * Suma de cartas del agente es 6, dealer muestra un 7, agente no tiene tiene un as\n",
        "  * Suma de cartas del agente es 19, dealer muestra un 3, agente tiene tiene un as\n",
        "\n",
        "* ¿Son coherentes sus acciones con las reglas del juego?\n",
        "\n",
        "Hint: ¿A que clase de python pertenecen los estados? Pruebe a usar el método `.reset` para saberlo."
      ],
      "metadata": {
        "id": "RO-EsAaPAYEm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "state = env.reset()\n",
        "type(state)"
      ],
      "metadata": {
        "id": "Lssdp7AvGaRh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "480a0f4c-6b04-4825-81fe-8cd689fde4fb"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tuple"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_action, prediction_info = model.predict(np.array([6, 7, 0]), deterministic=True)\n",
        "predicted_action"
      ],
      "metadata": {
        "id": "Px3-oWSeXka3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c5f423d-af40-4f5c-eb7f-00cb157e8886"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(1)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "El modelo predice array(1), lo que significa que el agente debería pedir otra carta."
      ],
      "metadata": {
        "id": "WgP3B5UNXmyV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_action, prediction_info = model.predict(np.array([19, 3, 1]), deterministic=True)\n",
        "predicted_action"
      ],
      "metadata": {
        "id": "L6Y4MazVXpJm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "47d7a8e7-9122-404d-93fc-a55ba96e58c1"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(0)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "El modelo predice array(0), lo que significa que el agente no debería pedir otra carta."
      ],
      "metadata": {
        "id": "2a89M56UXrRt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Recordemos las reglas básicas para evaluar la coherencia:\n",
        "- El agente debe pedir otra carta si su suma de cartas es menor a 21 y no tiene un blackjack natural.\n",
        "- El agente puede *plantarse* si considera que su suma de cartas es lo suficientemente alta para ganar sin exceder 21. personalmente creo que desde 17 en adelante es weno :-)\n",
        "\n",
        "**Conclusiones**:\n",
        "- **Escenario 1**, el agente tiene una suma baja (6) frente a una carta fuerte del dealer (7), por lo tanto es coherente que el modelo sugiera pedir otra carta.\n",
        "- **Escenario 2**, el agente ya tiene una suma alta (19) y tiene un as, lo cual le da flexibilidad para decidir plantarse sin riesgo de pasarse de 21.\n",
        "\n",
        "Ambas acciones predichas por el modelo son coherentes con las reglas del juego según los escenarios presentados."
      ],
      "metadata": {
        "id": "ZtTPM5fHXtBe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **2.2 LunarLander**\n",
        "\n",
        "<p align=\"center\">\n",
        "  <img src=\"https://i.redd.it/097t6tk29zf51.jpg\"\n",
        "\" width=\"400\">\n",
        "</p>\n",
        "\n",
        "Similar a la sección 2.1, en esta sección usted se encargará de implementar una gente de RL que pueda resolver el ambiente `LunarLander`.\n"
      ],
      "metadata": {
        "id": "SEqCTqqroh03"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **2.2.1 Descripción de MDP (0.2 puntos)**\n"
      ],
      "metadata": {
        "id": "sk5VJVppXh3N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Comencemos preparando el ambiente:"
      ],
      "metadata": {
        "id": "XvAVq1wQIjLc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gymnasium as gym\n",
        "env = gym.make(\"LunarLander-v2\", render_mode = \"rgb_array\", continuous = True) # notar el parámetro continuous = True"
      ],
      "metadata": {
        "id": "Qb5PmadJIngR"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Entregue una breve descripción sobre el ambiente [LunarLander](https://gymnasium.farama.org/environments/box2d/lunar_lander/) y su formulación en MDP, distinguiendo de forma clara y concisa los estados, acciones y recompensas.\n",
        "* ¿Como se distinguen las acciones de este ambiente en comparación a `Blackjack`?\n",
        "* En la preparación del ambiente se especifica el parámetro `continuous = True`. ¿Que implicancias tiene esto sobre el ambiente?"
      ],
      "metadata": {
        "id": "LNERH-m8JYQb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "El MDP para Lunar Lander con `continuous=True` se puede describir de la siguiente manera:\n",
        "\n",
        "**Estados**: Vector de 8 dimensiones que contiene:\n",
        "  1. Coordenada x del módulo lunar\n",
        "  2. Coordenada y del módulo lunar\n",
        "  3. Velocidad lineal en x\n",
        "  4. Velocidad lineal en y\n",
        "  5. Ángulo del módulo lunar\n",
        "  6. Velocidad angular\n",
        "  7. Booleano indicando si la pierna izquierda está en contacto con el suelo\n",
        "  8. Booleano indicando si la pierna derecha está en contacto con el suelo\n",
        "\n",
        "**Acciones**: Espacio continuo representado como `Box(-1, +1, (2,), dtype=np.float32)`:\n",
        "  - Primera coordenada: Controla el acelerador del motor principal (0-100% de potencia)\n",
        "  - Segunda coordenada: Controla los propulsores laterales\n",
        "\n",
        "**Recompensas**:\n",
        "  - Aumenta cuanto más cerca está el módulo de la plataforma de aterrizaje\n",
        "  - Aumenta cuanto más lento se mueve el módulo\n",
        "  - Disminuye cuanto más inclinado está el módulo\n",
        "  - +10 puntos por cada pierna en contacto con el suelo\n",
        "  - -0.03 puntos por cada frame que un motor lateral está encendido\n",
        "  - -0.3 puntos por cada frame que el motor principal está encendido\n",
        "  - -100 puntos por estrellarse, +100 puntos por aterrizar con seguridad\n",
        "\n",
        "Las acciones en Lunar Lander son continuas, a diferencia de Blackjack donde eran discretas (pedir o plantarse). Esto permite un control más preciso, pero también hace que el espacio de acciones sea más complejo."
      ],
      "metadata": {
        "id": "DbpGahPcHAje"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **2.2.2 Generando un Baseline (0.2 puntos)**\n",
        "\n",
        "* Simule un escenario en donde se escojan acciones aleatorias. Repita esta simulación 10 veces y reporte el promedio y desviación de las recompensas.\n",
        "* ¿Cómo calificaría el performance de esta política?\n",
        "\n",
        " Este performance es tremendamente pobre. Una recompensa constante de -100 sugiere que el módulo se está estrellando en cada episodio, lo cual es el peor resultado posible, pero esperado para acciones aleatorias en un ambiente tan complejo."
      ],
      "metadata": {
        "id": "YChodtNQwzG2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "episodes = 10\n",
        "rewards = np.zeros(episodes)\n",
        "\n",
        "for episode in range(episodes):\n",
        "    obs, info = env.reset()\n",
        "    done = False\n",
        "\n",
        "    while not done:\n",
        "        action = env.action_space.sample()\n",
        "        obs, reward, done, _, info = env.step(action)\n",
        "\n",
        "    rewards[episode] = reward\n",
        "\n",
        "mean_reward = np.mean(rewards)\n",
        "std_reward = np.std(rewards)\n",
        "\n",
        "print(\"Mean reward:\", mean_reward)\n",
        "print(\"Standard deviation of rewards:\", std_reward)\n"
      ],
      "metadata": {
        "id": "pNMT_GORIreW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a847eeaa-259c-43c6-e185-a5160d9e3dba"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean reward: -100.0\n",
            "Standard deviation of rewards: 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **2.2.3 Entrenamiento de modelo (0.2 puntos)**\n",
        "\n",
        "* A partir del siguiente [enlace](https://stable-baselines3.readthedocs.io/en/master/guide/algos.html), escoja un modelo de `stable_baselines3` y entrenelo para resolver el ambiente `LunarLander` **usando 10000 timesteps de entrenamiento**."
      ],
      "metadata": {
        "id": "hQrZVQflX_5f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from stable_baselines3 import SAC\n",
        "from stable_baselines3.common.evaluation import evaluate_policy\n",
        "\n",
        "# Instantiate the agent\n",
        "model = SAC(\"MlpPolicy\", env, verbose=0)\n",
        "\n",
        "# Train the agent and display a progress bar\n",
        "model.learn(total_timesteps=int(1e4), progress_bar=True)"
      ],
      "metadata": {
        "id": "Mg0epSnLKfy6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51,
          "referenced_widgets": [
            "bc0902664d034f73bf68eb28603a21a2",
            "9e6867520f7145b7bb513e2204466cec"
          ]
        },
        "outputId": "97e501d8-778a-48e1-f4b2-879f9ba2d003"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Output()"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bc0902664d034f73bf68eb28603a21a2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<stable_baselines3.sac.sac.SAC at 0x784edc6744f0>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **2.2.4 Evaluación de modelo (0.2 puntos)**\n",
        "\n",
        "* Repita el ejercicio 2.2.2 pero utilizando el modelo entrenado.\n",
        "* ¿Cómo es el performance de su agente? ¿Es mejor o peor que el escenario baseline?"
      ],
      "metadata": {
        "id": "3z-oIUSrlAsY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from stable_baselines3.common.evaluation import evaluate_policy\n",
        "\n",
        "mean_reward, std_reward = evaluate_policy(model, env, n_eval_episodes = 50)\n",
        "mean_reward, std_reward"
      ],
      "metadata": {
        "id": "CWVY1a39KeRs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d8d6abf-4a58-4888-b023-9c04ad328493"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(-245.62136531946098, 163.17298812826402)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "El algoritmo SAC muestra un rendimiento promedio de -245.621, considerablemente peor que el baseline de -100 y un desempeño inconsistente con alta variabilidad (desviación estándar de 163.172 frente a 0 del baseline). Este resultado sugiere que el agente SAC podría estar tomando acciones poco inteligentes en lugar de mejorar la situación, posiblemente debido a malos ajustes en los hiperparámetros."
      ],
      "metadata": {
        "id": "CZ2mxUdIX9rl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **2.2.5 Optimización de modelo (0.2 puntos)**\n",
        "\n",
        "* Repita los ejercicios 2.2.3 y 2.2.4 hasta obtener un nivel de recompensas promedio mayor a 50. Para esto, puede cambiar manualmente parámetros como:\n",
        "  - `total_timesteps`\n",
        "  - `learning_rate`\n",
        "  - `batch_size`\n",
        "\n",
        "* Una vez optimizado el modelo, use la función `export_gif` entregada para estudiar el comportamiento de su agente en la resolución del ambiente, comente sobre sus resultados.\n",
        "\n",
        "* Adjunte el gif generado en su entrega. Si, además, adjuntan el gif en el markdown tendrán un bonus de 0.1."
      ],
      "metadata": {
        "id": "x6Xw4YHT3P5d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se demoro mucho en correo y nos explotó el pc a ambas. NO CORRER, GRANADA! 🚀🔥🧨🤯"
      ],
      "metadata": {
        "id": "xSK6fcHWb7iM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from stable_baselines3 import SAC\n",
        "from stable_baselines3.common.evaluation import evaluate_policy\n",
        "\n",
        "# Instantiate the agent\n",
        "model = SAC(\"MlpPolicy\", env, verbose=0)\n",
        "\n",
        "# Train the agent and display a progress bar\n",
        "model.learn(total_timesteps=int(2e5), progress_bar=True)\n",
        "\n",
        "mean_reward, std_reward = evaluate_policy(model, env, n_eval_episodes = 10)\n",
        "mean_reward, std_reward"
      ],
      "metadata": {
        "id": "w6nIf3C5YAd6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import imageio\n",
        "import numpy as np\n",
        "\n",
        "def export_gif(model, n = 5):\n",
        "  '''\n",
        "  función que exporta a gif el comportamiento del agente en n episodios\n",
        "  '''\n",
        "  images = []\n",
        "  for episode in range(n):\n",
        "    obs = model.env.reset()\n",
        "    img = model.env.render()\n",
        "    done = False\n",
        "    while not done:\n",
        "      images.append(img)\n",
        "      action, _ = model.predict(obs)\n",
        "      obs, reward, done, info = model.env.step(action)\n",
        "      img = model.env.render(mode=\"rgb_array\")\n",
        "\n",
        "  imageio.mimsave(\"agent_performance.gif\", [np.array(img) for i, img in enumerate(images) if i%2 == 0], fps=29)"
      ],
      "metadata": {
        "id": "Ag-QIrmhLIY_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# escriba su respuesta acá"
      ],
      "metadata": {
        "id": "aItYF6sr6F_6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}